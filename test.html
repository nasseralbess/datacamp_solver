<!doctype html><html lang="en"><head><meta charset="UTF-8"><link rel="apple-touch-icon-precomposed" sizes="57x57" href="/campus/apple-touch-icon-57x57.png"><link rel="apple-touch-icon-precomposed" sizes="114x114" href="/campus/apple-touch-icon-114x114.png"><link rel="apple-touch-icon-precomposed" sizes="72x72" href="/campus/apple-touch-icon-72x72.png"><link rel="apple-touch-icon-precomposed" sizes="144x144" href="/campus/apple-touch-icon-144x144.png"><link rel="apple-touch-icon-precomposed" sizes="60x60" href="/campus/apple-touch-icon-60x60.png"><link rel="apple-touch-icon-precomposed" sizes="120x120" href="/campus/apple-touch-icon-120x120.png"><link rel="apple-touch-icon-precomposed" sizes="76x76" href="/campus/apple-touch-icon-76x76.png"><link rel="apple-touch-icon-precomposed" sizes="152x152" href="/campus/apple-touch-icon-152x152.png"><link rel="icon" type="image/png" href="/campus/favicon.ico"><link rel="icon" type="image/png" href="/campus/favicon-196x196.png" sizes="196x196"><link rel="icon" type="image/png" href="/campus/favicon-96x96.png" sizes="96x96"><link rel="icon" type="image/png" href="/campus/favicon-32x32.png" sizes="32x32"><link rel="icon" type="image/png" href="/campus/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="/campus/favicon-128.png" sizes="128x128"><meta name="application-name" content="DataCamp"><meta name="msapplication-TileColor" content="#FFFFFF"><meta name="msapplication-TileImage" content="/campus/mstile-144x144.png"><meta name="msapplication-square70x70logo" content="/campus/mstile-70x70.png"><meta name="msapplication-square150x150logo" content="/campus/mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="/campus/mstile-310x150.png"><meta name="msapplication-square310x310logo" content="/campus/mstile-310x310.png"><script>!function(n,t,e,r){function a(){return t&&t.now?t.now():null}e.version||(e._events=[],e._errors=[],e._metadata={},e._urlGroup=null,window.RM=e,e.install=function(t){e._options=t;var r=n.createElement("script");r.async=!0,r.crossOrigin="anonymous",r.src="https://cdn.requestmetrics.com/agent/current/rm.js";var a=n.getElementsByTagName("script")[0];a.parentNode.insertBefore(r,a)},e.identify=function(n,t){e._userId=n,e._identifyOptions=t},e.sendEvent=function(n,t){e._events.push({eventName:n,metadata:t,time:a()})},e.setUrlGroup=function(n){e._urlGroup=n},e.track=function(n,t){e._errors.push({error:n,metadata:t,time:a()})},e.addMetadata=function(n){e._metadata=Object.assign(e._metadata,n)})}(document,window.performance,window.RM||{}),window.RM.install({token:"h4zx2kc:w3sn5gv"})</script><script src="https://cdn.jsdelivr.net/pyodide/v0.26.4/full/pyodide.js"></script><script src="https://cdn.onesignal.com/sdks/web/v16/OneSignalSDK.page.js" defer="defer"></script><script>window.OneSignalDeferred=window.OneSignalDeferred||[],OneSignalDeferred.push((async function(e){await e.init({appId:"aea52b46-46e6-4e52-8d78-e7c3dee32ac5"})}))</script><link href="/campus/static/css/vendors~main~977b87ed.ad1a7104.chunk.css" rel="stylesheet"><link href="/campus/static/css/vendors~main~1f20a385.ead2d232.chunk.css" rel="stylesheet"><link href="/campus/static/css/vendors~main~678f84af.9b5ca43c.chunk.css" rel="stylesheet"><link href="/campus/static/css/main~c714bc7b.473de2c9.chunk.css" rel="stylesheet"><title data-react-helmet="true">Analyzing the sentiment of a review | Python</title><link data-react-helmet="true" rel="preload" href="https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSansRegular-english-v2.woff2" as="font" crossorigin="anonymous"><link data-react-helmet="true" rel="preload" href="https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSans-Semibold-english.woff2" as="font" crossorigin="anonymous"><link data-react-helmet="true" rel="preload" href="https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSansRegular-latin-v2.woff2" as="font" crossorigin="anonymous"><link data-react-helmet="true" rel="preload" href="https://dcmfe.datacamp.com/assets/fonts/JetBrainsMono-english.woff2" as="font" crossorigin="anonymous"><link data-react-helmet="true" rel="preload" href="https://dcmfe.datacamp.com/assets/fonts/JetBrainsMono-rest.woff2" as="font" crossorigin="anonymous"><link data-react-helmet="true" rel="preconnect" href="https://campus-api.datacamp.com"><link data-react-helmet="true" rel="dns-prefetch" href="https://campus-api.datacamp.com"><link data-react-helmet="true" rel="preconnect" href="https://projector.datacamp.com"><link data-react-helmet="true" rel="dns-prefetch" href="https://projector.datacamp.com"><link data-react-helmet="true" rel="preconnect" href="https://assets.datacamp.com"><link data-react-helmet="true" rel="dns-prefetch" href="https://assets.datacamp.com"><meta data-react-helmet="true" http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta data-react-helmet="true" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta data-react-helmet="true" name="fragment" content="!"><meta data-react-helmet="true" name="keywords" content="R, Python, Data analysis, interactive, learning"><meta data-react-helmet="true" name="description" content="Here is an example of Analyzing the sentiment of a review: Your team is building a tool to monitor customer sentiment in product reviews."><meta data-react-helmet="true" name="twitter:card" content="summary"><meta data-react-helmet="true" name="twitter:site" content="@DataCamp"><meta data-react-helmet="true" name="twitter:title" content="Analyzing the sentiment of a review | Python"><meta data-react-helmet="true" name="twitter:description" content="Here is an example of Analyzing the sentiment of a review: Your team is building a tool to monitor customer sentiment in product reviews."><meta data-react-helmet="true" name="twitter:creator" content="@DataCamp"><meta data-react-helmet="true" name="twitter:image:src" content="/public/assets/images/var/twitter_share.png"><meta data-react-helmet="true" name="twitter:domain" content="www.datacamp.com"><meta data-react-helmet="true" property="og:title" content="Analyzing the sentiment of a review | Python"><meta data-react-helmet="true" property="og:image" content="/public/assets/images/var/linkedin_share.png"><meta data-react-helmet="true" name="google-signin-clientid" content="892114885437-01a7plbsu1b2vobuhvnckmmanhb58h3a.apps.googleusercontent.com"><meta data-react-helmet="true" name="google-signin-scope" content="email profile"><meta data-react-helmet="true" name="google-signin-cookiepolicy" content="single_host_origin"><meta content="en" http-equiv="content-language"><link href="https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2" hreflang="x-default" rel="alternate"><link href="https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2" hreflang="en" rel="alternate"><link href="https://campus.datacamp.com/es/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2" hreflang="es" rel="alternate"><link href="https://campus.datacamp.com/pt/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2" hreflang="pt" rel="alternate"><link href="https://campus.datacamp.com/de/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2" hreflang="de" rel="alternate"></head><body><script>window.PRELOADED_STATE = "[&quot;~#iR&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;StateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;backendSession&quot;,[&quot;^ &quot;,&quot;status&quot;,[&quot;^ &quot;,&quot;code&quot;,&quot;none&quot;,&quot;text&quot;,&quot;&quot;],&quot;lastSubmittedCode&quot;,null,&quot;lastSubmittedCommand&quot;,null,&quot;isInitSession&quot;,false,&quot;message&quot;,null,&quot;sessionId&quot;,null],&quot;backendSessionJsonRpc&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;initial&quot;],&quot;boot&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;BootStateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;bootState&quot;,&quot;PRE_BOOTED&quot;,&quot;error&quot;,null]]],&quot;chapter&quot;,[&quot;~#iOM&quot;,[&quot;current&quot;,[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,3,&quot;number_of_videos&quot;,3,&quot;slug&quot;,&quot;text-classification-with-hugging-face&quot;,&quot;last_updated_on&quot;,&quot;08/07/2025&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,10,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter3.pdf&quot;,&quot;title&quot;,&quot;Text Classification with Hugging Face&quot;,&quot;xp&quot;,850,&quot;is_last_chapter&quot;,false,&quot;id&quot;,133925,&quot;exercises&quot;,[&quot;~#iL&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Hugging Face pipelines for sentiment analysis&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Analyzing the sentiment of a review&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Batch classifying multiple reviews&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;TabExercise&quot;,&quot;title&quot;,&quot;Comparing models on labeled review data&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Zero-shot classification and QNLI&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Zero-shot classification of support tickets&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Does the text answer the question?&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Question similarity and grammatical correctness&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Detecting duplicate questions&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Checking grammatical correctness&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;Harness the power of pre-trained models to perform advanced text classification tasks. Use Hugging Face pipelines for sentiment analysis, topic classification, and natural language inference. Evaluate semantic similarity and grammatical correctness with state-of-the-art models, all without building anything from scratch.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]]]],&quot;codeExplanation&quot;,[&quot;^ &quot;,&quot;^A&quot;,[&quot;^ &quot;,&quot;type&quot;,&quot;initial&quot;]],&quot;contentAuthorization&quot;,[&quot;^ &quot;],&quot;datawarehouseSession&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;initial&quot;],&quot;course&quot;,[&quot;^?&quot;,[&quot;difficulty_level&quot;,2,&quot;private_access&quot;,[&quot;^?&quot;,[]],&quot;content_branding&quot;,&quot;DataCamp&quot;,&quot;reduced_outline&quot;,null,&quot;course_resources&quot;,[&quot;^@&quot;,[]],&quot;marketing_video&quot;,&quot;&quot;,&quot;tier&quot;,2,&quot;private&quot;,false,&quot;mobile_enabled&quot;,true,&quot;author_field&quot;,null,&quot;chapters&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,1,&quot;number_of_videos&quot;,3,&quot;slug&quot;,&quot;text-processing-fundamentals&quot;,&quot;last_updated_on&quot;,&quot;08/07/2025&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,10,&quot;free_preview&quot;,true,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter1.pdf&quot;,&quot;title&quot;,&quot;Text Processing Fundamentals&quot;,&quot;xp&quot;,850,&quot;id&quot;,133923,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Introduction to natural language processing&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;TabExercise&quot;,&quot;title&quot;,&quot;Sentence and word tokenization&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;DragAndDropExercise&quot;,&quot;title&quot;,&quot;NLP workflow&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Stop words and punctuation handling&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Removing stop words&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Removing punctuation&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Text normalization techniques&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Lowercasing&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Stemming&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Lemmatization&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;Learn the essentials of text processing in Natural Language Processing (NLP). Master techniques such as tokenization, stop word and punctuation removal, and text normalization with lowercasing, stemming, and lemmatization to prepare text data for further analysis and insight extraction.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,2,&quot;number_of_videos&quot;,3,&quot;slug&quot;,&quot;feature-extraction-from-text&quot;,&quot;last_updated_on&quot;,&quot;08/07/2025&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,11,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter2.pdf&quot;,&quot;title&quot;,&quot;Feature Extraction from Text&quot;,&quot;xp&quot;,950,&quot;id&quot;,133924,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Bag-of-Words representation&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Building vocabulary from customer reviews&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Transforming text to numbers with BoW&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;TabExercise&quot;,&quot;title&quot;,&quot;Frequency analysis of product reviews&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Visualizing word frequencies&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;TF-IDF vectorization&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;TF-IDF representation of product feedback&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;BulletExercise&quot;,&quot;title&quot;,&quot;Comparing BoW and TF-IDF representations&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Embeddings&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Exploring word relationships with embeddings&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;BulletExercise&quot;,&quot;title&quot;,&quot;Visualizing and comparing word embeddings&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=11&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;Transform raw text into powerful numerical features. Create Bag-of-Words and TF-IDF representations to capture word importance across documents, then explore word embeddings like Word2Vec and GloVe to uncover deep semantic patterns. Visualize frequency, relevance, and similarity to bring your text data to life.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,3,&quot;number_of_videos&quot;,3,&quot;slug&quot;,&quot;text-classification-with-hugging-face&quot;,&quot;last_updated_on&quot;,&quot;08/07/2025&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,10,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter3.pdf&quot;,&quot;title&quot;,&quot;Text Classification with Hugging Face&quot;,&quot;xp&quot;,850,&quot;id&quot;,133925,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Hugging Face pipelines for sentiment analysis&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Analyzing the sentiment of a review&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,null,&quot;aggregate_xp&quot;,50,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Batch classifying multiple reviews&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;TabExercise&quot;,&quot;title&quot;,&quot;Comparing models on labeled review data&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Zero-shot classification and QNLI&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Zero-shot classification of support tickets&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Does the text answer the question?&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Question similarity and grammatical correctness&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Detecting duplicate questions&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Checking grammatical correctness&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;Harness the power of pre-trained models to perform advanced text classification tasks. Use Hugging Face pipelines for sentiment analysis, topic classification, and natural language inference. Evaluate semantic similarity and grammatical correctness with state-of-the-art models, all without building anything from scratch.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,4,&quot;number_of_videos&quot;,4,&quot;slug&quot;,&quot;token-classification-and-text-generation&quot;,&quot;last_updated_on&quot;,&quot;08/07/2025&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,11,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter4.pdf&quot;,&quot;title&quot;,&quot;Token Classification and Text Generation&quot;,&quot;xp&quot;,900,&quot;id&quot;,133926,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Token classification&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Identifying named entities in news headlines&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Part of Speech tagging for text analysis&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Question answering&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Answering questions from product descriptions&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Generating natural answers with abstractive QA&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Sequence generation tasks&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Summarizing news articles for quick insights&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Translating customer reviews to French&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Building a search completion system&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Congratulations&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=11&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;Dive into the core of modern NLP applications with token classification and text generation techniques. Learn to extract meaningful entities and grammatical structures using NER and PoS tagging. Master both extractive and abstractive question answering, and explore advanced generation tasks including summarization, translation, and language modeling using Hugging Face pipelines.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]]]],&quot;author_image&quot;,&quot;placeholder.png&quot;,&quot;tracks&quot;,[&quot;^@&quot;,[]],&quot;has_variant_traditional&quot;,true,&quot;runtime_config&quot;,&quot;learn-heavy&quot;,&quot;lti_only&quot;,false,&quot;image_url&quot;,&quot;https://assets.datacamp.com/production/default/shields/placeholder.png&quot;,&quot;topic_id&quot;,16,&quot;slug&quot;,&quot;natural-language-processing-nlp-in-python&quot;,&quot;restricted_reasons&quot;,[&quot;^@&quot;,[]],&quot;hide_openai_branding&quot;,true,&quot;last_updated_on&quot;,&quot;07/10/2025&quot;,&quot;audio_recorders&quot;,[&quot;^@&quot;,[]],&quot;paid&quot;,true,&quot;collaborators&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/002/582/square/20210323_102554_small2.jpg?1705586726&quot;,&quot;full_name&quot;,&quot;James Chapman&quot;]],[&quot;^?&quot;,[&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/002/714/square/myprofilephoto.jpeg?1705586799&quot;,&quot;full_name&quot;,&quot;Jasmin Ludolf&quot;]],[&quot;^?&quot;,[&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/users/avatars/014/780/775/square/%D0%9E%D0%B1%D1%8C%D1%8F%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%9A%D0%BE%D0%BD%D0%BA%D0%B8%D0%BD_%281%29.jpg?1711368550&quot;,&quot;full_name&quot;,&quot;Stan Konkin&quot;]]]],&quot;difficulty_level_hardcoded&quot;,true,&quot;time_needed_in_hours&quot;,4,&quot;technology_id&quot;,2,&quot;university&quot;,null,&quot;has_variant_ai_native&quot;,false,&quot;archived_at&quot;,null,&quot;state&quot;,&quot;live&quot;,&quot;content_area&quot;,&quot;Data Science and Analytics&quot;,&quot;cpe_credits&quot;,null,&quot;author_bio&quot;,null,&quot;duration_minutes&quot;,240,&quot;is_labeled_as_new&quot;,false,&quot;should_cache&quot;,true,&quot;sharing_links&quot;,[&quot;^?&quot;,[&quot;twitter&quot;,&quot;http://bit.ly/1eWTMJh&quot;,&quot;facebook&quot;,&quot;http://bit.ly/1iS42Do&quot;]],&quot;instructors&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;id&quot;,10350864,&quot;marketing_biography&quot;,&quot;Machine Learning Engineer&quot;,&quot;biography&quot;,&quot;Fouad is an experienced ML engineer, researcher, and educator, currently pursuing a Ph.D. in applied ML, with a focus on cybersecurity applications. His talent lies in simplifying complex data science concepts, making them accessible to everyone.&quot;,&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/003/004/square/1683950699469.jpg?1705586868&quot;,&quot;full_name&quot;,&quot;Fouad Trad&quot;,&quot;instructor_path&quot;,&quot;/instructors/fat10&quot;]]]],&quot;translated_course_id&quot;,41242,&quot;seo_title&quot;,&quot;Natural Language Processing (NLP) in Python&quot;,&quot;industry_ids&quot;,[&quot;^@&quot;,[]],&quot;title&quot;,&quot;Natural Language Processing (NLP) in Python&quot;,&quot;xp&quot;,3550,&quot;image_thumbnail_url&quot;,&quot;https://assets.datacamp.com/production/default/shields/placeholder.png&quot;,&quot;short_description&quot;,&quot;Master text analysis with essential NLP techniques from preprocessing to advanced transformer models. &quot;,&quot;aiFeatureFlags&quot;,[&quot;^?&quot;,[&quot;aiErrorExplanationEnabled&quot;,true,&quot;aiExplainSolutionEnabled&quot;,true,&quot;aiHintsOrIncorrectSubmitionEnabled&quot;,true]],&quot;nb_of_subscriptions&quot;,2119,&quot;long_description&quot;,&quot;&lt;h2&gt;Build a Strong NLP Foundation &lt;/h2&gt;Unlock the power of Natural Language Processing (NLP) and take your text analysis skills to the next level! This course equips you with essential tools to process, analyze, and extract insights from text data. Start with the fundamentals of text processing, from tokenization to cleaning and normalizing text by removing stop words, punctuation, and applying lemmatization and stemming to improve text consistency.&lt;br&gt;&lt;br&gt;&lt;h2&gt;Extract Meaningful Features from Text&lt;/h2&gt;Go beyond raw text and transform it into numerical representations! Explore the Bag-of-Words representation, dive into TF-IDF vectorization, and leverage powerful word embeddings like Word2Vec and GloVe to capture semantic relationships between words.&lt;br&gt;&lt;br&gt;&lt;h2&gt;Classify and Generate Text with AI&lt;/h2&gt;Harness the power of state-of-the-art transformer models using Hugging Face pipelines. Learn how to perform sentiment analysis, classify content, analyze question-answer relationships, assess grammatical acceptability, and generate text using various models. Explore Named Entity Recognition (NER), Part-of-Speech (PoS) tagging, text summarization, and translation to expand your NLP toolkit.&lt;br&gt;&lt;br&gt;&lt;h2&gt;Master key NLP libraries&lt;/h2&gt;By the end of this course, you’ll have a strong grasp of NLP fundamentals and hands-on experience with key libraries such as nltk, sklearn, gensim, and Hugging Face’s transformers. Start your journey today and transform the way you interact with text data!&quot;,&quot;seo_description&quot;,&quot;Master text analysis with essential NLP techniques from preprocessing to advanced transformer models. &quot;,&quot;type&quot;,&quot;datacamp&quot;,&quot;link&quot;,&quot;https://www.datacamp.com/courses/natural-language-processing-nlp-in-python&quot;,&quot;case_study&quot;,false,&quot;restricted&quot;,false,&quot;id&quot;,41242,&quot;learning_objectives&quot;,[&quot;^@&quot;,[]],&quot;datasets&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/7025/datasets/b3f14ad8963bf73caf65e0f5ae4eab5bdc123f63/product_reviews.csv&quot;,&quot;name&quot;,&quot;product_reviews.csv&quot;]]]],&quot;description&quot;,&quot;Unlock the power of Natural Language Processing (NLP) and take your text analysis skills to the next level! This course equips you with essential tools to process, analyze, and extract insights from text data. Start with the fundamentals of text processing, such as tokenization, lemmatization, and stemming, to extracting meaningful numerical features from text using bag-of-words (BoW), TF-IDF, and embeddings. Finally, harness the power of state-of-the-art transformer models using Hugging Face. Perform sentiment analysis, classify content, analyze question-answer relationships, assess grammatical acceptability, and generate text using the latest models.&quot;,&quot;prerequisites&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;path&quot;,&quot;/courses/python-toolbox&quot;,&quot;title&quot;,&quot;Python Toolbox&quot;]]]],&quot;content_updated_at&quot;,&quot;2025-07-08T09:25:45Z&quot;,&quot;original_image_url&quot;,&quot;https://assets.datacamp.com/production/default/shields/placeholder.png&quot;,&quot;programming_language&quot;,&quot;python&quot;,&quot;external_slug&quot;,&quot;natural-language-processing-nlp-in-python&quot;]],&quot;exercises&quot;,[&quot;^?&quot;,[&quot;current&quot;,1,&quot;all&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,1918984,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,&quot;learn-heavy&quot;,&quot;number&quot;,1,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.35910499165883913,&quot;chapter_id&quot;,133925,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;Hugging Face pipelines for sentiment analysis&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,1918984,&quot;projector_key&quot;,&quot;course_41242_087144e37d58af08ee7becba96827870&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;046569f077&quot;,&quot;course_id&quot;,41242]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Define the sentiment analysis pipeline\\nclassifier = ____\\n\\nreview_text = \\&quot;The new update made the app much faster and easier to use!\\&quot;\\n\\n# Get sentiment prediction\\nresult = ____\\n\\nprint(result)&quot;,&quot;sct&quot;,&quot;# Examples of good success messages: https://instructor-support.datacamp.com/en/articles/2299773-exercise-success-messages.\\n\\nsig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n  check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n  check_object(\\&quot;review_text\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n  check_function(&#39;print&#39;).check_args(0).has_equal_value(incorrect_msg=\\&quot;Did you print the `result` variable?\\&quot;)\\n) \\n\\nsuccess_msg(\\&quot;Well done! You&#39;ve classified a single review. Let’s scale this to multiple reviews next.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a &lt;code&gt;pipeline&lt;/code&gt; for &lt;code&gt;sentiment-analysis&lt;/code&gt; with the &lt;code&gt;\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;&lt;/code&gt; model.&lt;/li&gt;\\n&lt;li&gt;Use the &lt;code&gt;pipeline&lt;/code&gt; to classify the sentiment of &lt;code&gt;review_text&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,1918985,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;A &lt;code&gt;pipeline&lt;/code&gt; takes two arguments: &lt;code&gt;task&lt;/code&gt; and &lt;code&gt;model&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;To classify the sentiment of a &lt;code&gt;review_text&lt;/code&gt;, pass it directly into the &lt;code&gt;pipeline&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,2,&quot;user&quot;,[&quot;^?&quot;,[&quot;isHintShown&quot;,false,&quot;usedAiFeatures&quot;,[&quot;^?&quot;,[&quot;aiIncorrectSubmissions&quot;,false,&quot;aiErrorExplanations&quot;,false]],&quot;lastRunCode&quot;,null,&quot;editorTabs&quot;,[&quot;^?&quot;,[&quot;files/script.py&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;script.py&quot;,&quot;isSolution&quot;,false,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true,&quot;isClosable&quot;,false,&quot;code&quot;,null,&quot;extra&quot;,[&quot;^?&quot;,[]]]]]]]],&quot;outputMarkdownTabs&quot;,[&quot;^?&quot;,[]],&quot;markdown&quot;,[&quot;^?&quot;,[&quot;titles&quot;,[&quot;^@&quot;,[&quot;Knit PDF&quot;,&quot;Knit HTML&quot;]],&quot;activeTitle&quot;,&quot;Knit HTML&quot;]],&quot;currentXp&quot;,100,&quot;graphicalTabs&quot;,[&quot;^?&quot;,[&quot;plot&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;animation--flash&quot;,&quot;title&quot;,&quot;Plots&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;sources&quot;,[&quot;^@&quot;,[]],&quot;currentIndex&quot;,0]],&quot;dimension&quot;,[&quot;^?&quot;,[&quot;isRealSize&quot;,false,&quot;width&quot;,1,&quot;height&quot;,1]]]],&quot;html&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;animation--flash&quot;,&quot;title&quot;,&quot;HTML Viewer&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;sources&quot;,[&quot;^@&quot;,[]],&quot;currentIndex&quot;,0]]]]]],&quot;feedbackMessages&quot;,[&quot;^@&quot;,[]],&quot;lastSubmittedCode&quot;,null,&quot;ltiStatus&quot;,[&quot;^?&quot;,[]],&quot;lastSubmitActiveEditorTab&quot;,null,&quot;consoleSqlTabs&quot;,[&quot;^?&quot;,[&quot;query_result&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;&quot;,&quot;title&quot;,&quot;query result&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true,&quot;isNotView&quot;,true,&quot;message&quot;,&quot;No query executed yet...&quot;]]]]]],&quot;consoleTabs&quot;,[&quot;^?&quot;,[&quot;console&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;IPython Shell&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true]],&quot;dimension&quot;,[&quot;^?&quot;,[&quot;cols&quot;,400]]]],&quot;slides&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;Slides&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,false]]]]]],&quot;inputMarkdownTabs&quot;,[&quot;^?&quot;,[]],&quot;consoleObjectViewTabs&quot;,[&quot;^?&quot;,[]]]],&quot;randomNumber&quot;,0.25550630139871777,&quot;assignment&quot;,&quot;&lt;p&gt;Your team is building a tool to monitor customer sentiment in product reviews. As a first step, you&#39;re testing the sentiment of individual reviews using a pre-trained pipeline.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;sample_codes&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;difficulty&quot;,0,&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Define the sentiment analysis pipeline\\nclassifier = ____\\n\\nreview_text = \\&quot;The new update made the app much faster and easier to use!\\&quot;\\n\\n# Get sentiment prediction\\nresult = ____\\n\\nprint(result)&quot;]]]],&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Analyzing the sentiment of a review&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;solution&quot;,&quot;from transformers import pipeline\\n\\n# Define the sentiment analysis pipeline\\nclassifier = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\n\\nreview_text = \\&quot;The new update made the app much faster and easier to use!\\&quot;\\n\\n# Get sentiment prediction\\nresult = classifier(review_text)\\n\\nprint(result)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,1918985,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\nclassifier = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\n\\nreview_batch = [\\n    \\&quot;Absolutely love the new design!\\&quot;,\\n    \\&quot;The app crashes every time I open it.\\&quot;,\\n    \\&quot;Customer support was helpful and quick.\\&quot;,\\n    \\&quot;Too many ads make it unusable.\\&quot;,\\n    \\&quot;Everything works fine, but it’s a bit slow.\\&quot;\\n]\\n\\n# Classify sentiments\\nresults = ____\\nprint(results)&quot;,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;review_batch\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `review_batch` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n  check_function(&#39;print&#39;).check_args(0).has_equal_value(incorrect_msg=\\&quot;Did you print the `result` variable?\\&quot;)\\n) \\nsuccess_msg(\\&quot;Nice! You&#39;ve classified a batch of reviews. Now let&#39;s compare how two different models perform on the same dataset.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a &lt;code&gt;pipeline&lt;/code&gt; for &lt;code&gt;sentiment-analysis&lt;/code&gt; using &lt;code&gt;\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the &lt;code&gt;pipeline&lt;/code&gt; to classify all reviews in the &lt;code&gt;review_batch&lt;/code&gt; list.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,1918986,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;The pipeline can accept a list of strings to return a list of results.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,3,&quot;randomNumber&quot;,0.20526280162907096,&quot;assignment&quot;,&quot;&lt;p&gt;Your sentiment analysis pipeline works well on one review. Now it&#39;s time to handle multiple reviews in one batch. This is a key step before analyzing user feedback at scale.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;sample_codes&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;difficulty&quot;,0,&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\nclassifier = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\n\\nreview_batch = [\\n    \\&quot;Absolutely love the new design!\\&quot;,\\n    \\&quot;The app crashes every time I open it.\\&quot;,\\n    \\&quot;Customer support was helpful and quick.\\&quot;,\\n    \\&quot;Too many ads make it unusable.\\&quot;,\\n    \\&quot;Everything works fine, but it’s a bit slow.\\&quot;\\n]\\n\\n# Classify sentiments\\nresults = ____\\nprint(results)&quot;]]]],&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Batch classifying multiple reviews&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;solution&quot;,&quot;from transformers import pipeline\\n\\nclassifier = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\n\\nreview_batch = [\\n    \\&quot;Absolutely love the new design!\\&quot;,\\n    \\&quot;The app crashes every time I open it.\\&quot;,\\n    \\&quot;Customer support was helpful and quick.\\&quot;,\\n    \\&quot;Too many ads make it unusable.\\&quot;,\\n    \\&quot;Everything works fine, but it’s a bit slow.\\&quot;\\n]\\n\\n# Classify sentiments\\nresults = classifier(review_batch)\\nprint(results)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,1918986,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;instructions&quot;,null,&quot;externalId&quot;,1918987,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,4,&quot;randomNumber&quot;,0.12333672235765003,&quot;assignment&quot;,&quot;&lt;p&gt;Now that you can classify sentiment in bulk, your team wants to evaluate which model is more reliable. You&#39;ll compare two models using a larger labeled dataset of reviews and measure their accuracy.&lt;/p&gt;\\n&lt;p&gt;A &lt;code&gt;texts&lt;/code&gt; list and its &lt;code&gt;true_labels&lt;/code&gt; are pre-loaded for you.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Comparing models on labeled review data&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;texts = [\\n    \\&quot;I can&#39;t believe how great this app is, it’s honestly a game-changer!\\&quot;,       \\n    \\&quot;It’s not as bad as I expected, but still not great.\\&quot;,                     \\n    \\&quot;The update did fix a lot of issues, so I’m glad they listened to feedback.\\&quot;,\\n    \\&quot;It’s just another buggy version with more problems than before.\\&quot;,        \\n    \\&quot;I&#39;m amazed by how quickly it works now, truly impressed.\\&quot;,                \\n    \\&quot;Oh look, the app works for once. Not sure if it&#39;s a fluke or progress.\\&quot;,  \\n    \\&quot;The new design is a pleasant surprise — I didn&#39;t expect it to be this good.\\&quot;, \\n    \\&quot;The app keeps freezing when I need it most. Terrible experience.\\&quot;,        \\n    \\&quot;I didn’t think it was possible, but this update made things even worse.\\&quot;,  \\n    \\&quot;Wow, finally an update that makes sense. So happy about this!\\&quot;,           \\n    \\&quot;At least the app doesn’t crash every five minutes now. That’s something.\\&quot;, \\n    \\&quot;I’ve never been so impressed by an app’s performance. Outstanding!\\&quot;,      \\n    \\&quot;I’m sure it works for some people, but not for me. A lot of problems.\\&quot;,    \\n    \\&quot;It’s almost like the developers actually care now. Big improvement!\\&quot;,     \\n    \\&quot;The app is still the same: slow, frustrating, and useless.\\&quot;,              \\n    \\&quot;The new features are cool, but the app is still very glitchy.\\&quot;,         \\n    \\&quot;I wish I had known about this app sooner, it really does make a difference.\\&quot;,\\n    \\&quot;I regret wasting my time on this app. I’ve had enough.\\&quot;,                 \\n    \\&quot;I’m so happy they fixed that bug, I didn’t realize how much it bothered me.\\&quot;, \\n    \\&quot;The app does some things right, but most of it is just annoying.\\&quot;        \\n]\\n\\ntrue_labels = [\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I can&#39;t believe how great this app is, it’s honestly a game-changer!\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;It’s not as bad as I expected, but still not great.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;The update did fix a lot of issues, so I’m glad they listened to feedback.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;It’s just another buggy version with more problems than before.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I&#39;m amazed by how quickly it works now, truly impressed.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;Oh look, the app works for once. Not sure if it&#39;s a fluke or progress.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;The new design is a pleasant surprise — I didn&#39;t expect it to be this good.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;The app keeps freezing when I need it most. Terrible experience.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;I didn’t think it was possible, but this update made things even worse.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;Wow, finally an update that makes sense. So happy about this!\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;At least the app doesn’t crash every five minutes now. That’s something.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I’ve never been so impressed by an app’s performance. Outstanding!\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;I’m sure it works for some people, but not for me. A lot of problems.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;It’s almost like the developers actually care now. Big improvement!\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;The app is still the same: slow, frustrating, and useless.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;The new features are cool, but the app is still very glitchy.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I wish I had known about this app sooner, it really does make a difference.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;I regret wasting my time on this app. I’ve had enough.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I’m so happy they fixed that bug, I didn’t realize how much it bothered me.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;The app does some things right, but most of it is just annoying.\\&quot;\\n]\\n\\nimport warnings\\nwarnings.filterwarnings(\\&quot;ignore\\&quot;)\\nfrom transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;TabExercise&quot;,&quot;id&quot;,1918987,&quot;subexercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, ____)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, ____)\\n\\n# Generate predictions\\npreds_a = [____ for res in pipe_a(texts)]\\npreds_b = [____ for res in pipe_b(texts)]&quot;,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n    check_function(\\&quot;transformers.pipeline\\&quot;, index=0, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_function(\\&quot;transformers.pipeline\\&quot;, index=1, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n\\n  has_code(\\&quot;preds_a\\\\s*=\\\\s*\\\\[\\\\s*res\\\\[\\\\s*(\\\\\\&quot;|\\\\&#39;)label(\\\\\\&quot;|\\\\&#39;)\\&quot;, not_typed_msg=\\&quot;Did you correctly extract the `&#39;label&#39;` using `res[&#39;label&#39;]` inside your first list comprehension?\\&quot;),\\n  has_code(\\&quot;preds_b\\\\s*=\\\\s*\\\\[\\\\s*res\\\\[\\\\s*(\\\\\\&quot;|\\\\&#39;)label(\\\\\\&quot;|\\\\&#39;)\\&quot;, not_typed_msg=\\&quot;Did you correctly extract the `&#39;label&#39;` using `res[&#39;label&#39;]` inside your second list comprehension?\\&quot;)\\n) &quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Load two pipelines (&lt;code&gt;pipe_a&lt;/code&gt; and &lt;code&gt;pipe_a&lt;/code&gt;) using the models &lt;code&gt;\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;&lt;/code&gt; and &lt;code&gt;\\&quot;abilfad/sentiment-binary-dicoding\\&quot;&lt;/code&gt;, respectively.&lt;/li&gt;\\n&lt;li&gt;Extract the &lt;code&gt;&#39;label&#39;&lt;/code&gt; values from the predictions of both pipelines.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;In the list comprehension, each &lt;code&gt;res&lt;/code&gt; is a dictionary with a &lt;code&gt;&#39;label&#39;&lt;/code&gt; and a &lt;code&gt;&#39;score&#39;&lt;/code&gt;. Extract the &lt;code&gt;&#39;label&#39;&lt;/code&gt; to get the predictions.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,1,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;sample_codes&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;difficulty&quot;,0,&quot;sample_code&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, ____)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, ____)\\n\\n# Generate predictions\\npreds_a = [____ for res in pipe_a(texts)]\\npreds_b = [____ for res in pipe_b(texts)]&quot;]]]],&quot;exercise_image&quot;,null,&quot;title&quot;,null,&quot;xp&quot;,50,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;abilfad/sentiment-binary-dicoding\\&quot;)\\n\\n# Generate predictions\\npreds_a = [res[\\&quot;label\\&quot;] for res in pipe_a(texts)]\\npreds_b = [res[\\&quot;label\\&quot;] for res in pipe_b(texts)]&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,1918988,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;abilfad/sentiment-binary-dicoding\\&quot;)\\n\\n# Generate predictions\\npreds_a = [res[\\&quot;label\\&quot;] for res in pipe_a(texts)]\\npreds_b = [res[\\&quot;label\\&quot;] for res in pipe_b(texts)]\\n\\n# Evaluate accuracies\\nacc_a = ____\\nacc_b = ____\\nprint(f\\&quot;Accuracy - Model A: {acc_a:.2f}\\&quot;)\\nprint(f\\&quot;Accuracy - Model B: {acc_b:.2f}\\&quot;)&quot;,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n    check_function(\\&quot;transformers.pipeline\\&quot;, index=0, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_function(\\&quot;transformers.pipeline\\&quot;, index=1, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n\\n  has_code(\\&quot;preds_a\\\\s*=\\\\s*\\\\[\\\\s*res\\\\[\\\\s*(\\\\\\&quot;|\\\\&#39;)label(\\\\\\&quot;|\\\\&#39;)\\&quot;, not_typed_msg=\\&quot;Did you correctly extract the `&#39;label&#39;` using `res[&#39;label&#39;]` inside your first list comprehension?\\&quot;),\\n  has_code(\\&quot;preds_b\\\\s*=\\\\s*\\\\[\\\\s*res\\\\[\\\\s*(\\\\\\&quot;|\\\\&#39;)label(\\\\\\&quot;|\\\\&#39;)\\&quot;, not_typed_msg=\\&quot;Did you correctly extract the `&#39;label&#39;` using `res[&#39;label&#39;]` inside your second list comprehension?\\&quot;),\\n  check_or(\\n    has_code(\\&quot;acc_a\\\\s*=\\\\s*accuracy_score\\\\(\\\\s*true_labels\\\\s*,\\\\s*preds_a\\&quot;, not_typed_msg=\\&quot;Did you correctly calculate `acc_a` by calling `accuracy_score(true_labels, preds_a)`?\\&quot;),\\n    has_code(\\&quot;acc_a\\\\s*=\\\\s*accuracy_score\\\\(\\\\s*preds_a\\\\s*,\\\\s*true_labels\\&quot;, not_typed_msg=\\&quot;Did you correctly calculate `acc_a` by calling `accuracy_score(true_labels, preds_a)`?\\&quot;)\\n  ),\\n  check_or(\\n    has_code(\\&quot;acc_b\\\\s*=\\\\s*accuracy_score\\\\(\\\\s*true_labels\\\\s*,\\\\s*preds_b\\&quot;, not_typed_msg=\\&quot;Did you correctly calculate `acc_b` by calling `accuracy_score(true_labels, preds_b)`?\\&quot;),\\n    has_code(\\&quot;acc_b\\\\s*=\\\\s*accuracy_score\\\\(\\\\s*preds_b\\\\s*,\\\\s*true_labels\\&quot;, not_typed_msg=\\&quot;Did you correctly calculate `acc_b` by calling `accuracy_score(true_labels, preds_b)`?\\&quot;)\\n  )\\n)\\n\\nsuccess_msg(\\&quot;Excellent! You&#39;ve compared two models using real review data. This kind of evaluation helps identify the most reliable option, and in this case, Model B appears to perform better for our tasks, so it should be chosen for production.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Compute the accuracies of both models (&lt;code&gt;acc_a&lt;/code&gt; and &lt;code&gt;acc_b&lt;/code&gt;).&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;The &lt;code&gt;accuracy_score&lt;/code&gt; function takes as inputs the &lt;code&gt;true_labels&lt;/code&gt; and the predictions.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,2,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;sample_codes&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;difficulty&quot;,0,&quot;sample_code&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;abilfad/sentiment-binary-dicoding\\&quot;)\\n\\n# Generate predictions\\npreds_a = [res[\\&quot;label\\&quot;] for res in pipe_a(texts)]\\npreds_b = [res[\\&quot;label\\&quot;] for res in pipe_b(texts)]\\n\\n# Evaluate accuracies\\nacc_a = ____\\nacc_b = ____\\nprint(f\\&quot;Accuracy - Model A: {acc_a:.2f}\\&quot;)\\nprint(f\\&quot;Accuracy - Model B: {acc_b:.2f}\\&quot;)&quot;]]]],&quot;exercise_image&quot;,null,&quot;title&quot;,null,&quot;xp&quot;,50,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;abilfad/sentiment-binary-dicoding\\&quot;)\\n\\n# Generate predictions\\npreds_a = [res[\\&quot;label\\&quot;] for res in pipe_a(texts)]\\npreds_b = [res[\\&quot;label\\&quot;] for res in pipe_b(texts)]\\n\\n# Evaluate accuracies\\nacc_a = accuracy_score(true_labels, preds_a)\\nacc_b = accuracy_score(true_labels, preds_b)\\nprint(f\\&quot;Accuracy - Model A: {acc_a:.2f}\\&quot;)\\nprint(f\\&quot;Accuracy - Model B: {acc_b:.2f}\\&quot;)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,1918989,&quot;programming_language&quot;,null]]]],&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,1918990,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,&quot;learn-heavy&quot;,&quot;number&quot;,5,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.9651857447035519,&quot;chapter_id&quot;,133925,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;Zero-shot classification and QNLI&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,1918990,&quot;projector_key&quot;,&quot;course_41242_c7803789f75d0048781b9d6b6c08a49e&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;395f17cdea&quot;,&quot;course_id&quot;,41242]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the zero-shot classifier\\nclassifier = ____\\n\\nticket_text = \\&quot;I was charged twice for my subscription this month. Can you please refund the extra charge?\\&quot;\\ncandidate_labels = [\\&quot;Billing\\&quot;, \\&quot;Technical Issue\\&quot;, \\&quot;Account Access\\&quot;]\\n\\n# Classify the ticket\\nresult = ____\\n\\nprint(result[&#39;labels&#39;])\\nprint(result[&#39;scores&#39;])&quot;,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;ticket_text\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `ticket_text` variable.\\&quot;),\\n  check_object(\\&quot;candidate_labels\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `candidate_labels` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n) \\n\\n\\nsuccess_msg(\\&quot;Great job! Based on the prediction probabilities, the model is most confident that this ticket belongs in the Billing category. This enables the company to automatically route tickets to the right team, reducing response time and improving customer satisfaction without needing to retrain models for each category.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Create a zero-shot &lt;code&gt;classifier&lt;/code&gt; pipeline using the &lt;code&gt;\\&quot;MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\\&quot;&lt;/code&gt; model.&lt;/li&gt;\\n&lt;li&gt;Use it to classify the &lt;code&gt;ticket_text&lt;/code&gt; into one of the categories listed in &lt;code&gt;candidate_labels&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,1918991,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use &lt;code&gt;zero-shot-classification&lt;/code&gt; as a task when defining the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;li&gt;Pass the &lt;code&gt;ticket_text&lt;/code&gt; and &lt;code&gt;candidate_labels&lt;/code&gt; as arguments to the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,6,&quot;randomNumber&quot;,0.7513952445580347,&quot;assignment&quot;,&quot;&lt;p&gt;A company receives hundreds of support tickets daily, covering topics like billing issues, technical problems, and account management. Manually sorting these tickets is inefficient. You&#39;ve been asked to use a zero-shot classification model to automatically categorize incoming ticket messages without needing a custom-trained classifier.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;sample_codes&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;difficulty&quot;,0,&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the zero-shot classifier\\nclassifier = ____\\n\\nticket_text = \\&quot;I was charged twice for my subscription this month. Can you please refund the extra charge?\\&quot;\\ncandidate_labels = [\\&quot;Billing\\&quot;, \\&quot;Technical Issue\\&quot;, \\&quot;Account Access\\&quot;]\\n\\n# Classify the ticket\\nresult = ____\\n\\nprint(result[&#39;labels&#39;])\\nprint(result[&#39;scores&#39;])&quot;]]]],&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Zero-shot classification of support tickets&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;solution&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the zero-shot classifier\\nclassifier = pipeline(task=\\&quot;zero-shot-classification\\&quot;, model=\\&quot;MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\\&quot;)\\n\\nticket_text = \\&quot;I was charged twice for my subscription this month. Can you please refund the extra charge?\\&quot;\\ncandidate_labels = [\\&quot;Billing\\&quot;, \\&quot;Technical Issue\\&quot;, \\&quot;Account Access\\&quot;]\\n\\n# Classify the ticket\\nresult = classifier(ticket_text, candidate_labels)\\n\\nprint(result[&#39;labels&#39;])\\nprint(result[&#39;scores&#39;])&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,1918991,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the QNLI pipeline\\nclassifier = ____\\n\\npassage = \\&quot;Our refund policy allows customers to return any item within 30 days of purchase, provided the item is in its original condition and accompanied by the receipt. Refunds are issued to the original payment method within 5–7 business days.\\&quot;\\nquestion = \\&quot;Can I get a refund if I return a product after 20 days?\\&quot;\\n\\n# Get the result\\nresult = ____\\nprint(result)&quot;,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;passage\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `ticket_text` variable.\\&quot;),\\n  check_object(\\&quot;question\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `candidate_labels` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\n  has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question` as the value for the `&#39;text&#39;` key in the classifier?\\&quot;),\\n  has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text_pair(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*passage\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `passage` as the value for the `&#39;text_pair&#39;` key in the classifier?\\&quot;)\\n)\\n\\n\\nsuccess_msg(\\&quot;Well done! Based on the QNLI model, the passage answers the question with a confidence of 97%. This solution helps the content moderation team automate knowledge validation and improves response accuracy on customer support platforms, ensuring users get timely and relevant answers.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a &lt;code&gt;classifier&lt;/code&gt; pipeline with a suitable QNLI model, such as &lt;code&gt;\\&quot;cross-encoder/qnli-electra-base\\&quot;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use this pipeline to evaluate whether the given &lt;code&gt;passage&lt;/code&gt; answers the &lt;code&gt;question&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,1918992,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;QNLI is a &lt;code&gt;\\&quot;text-classification\\&quot;&lt;/code&gt; task.&lt;/li&gt;\\n&lt;li&gt;Ensure the &lt;code&gt;passage&lt;/code&gt; and &lt;code&gt;question&lt;/code&gt; are passed in a dictionary, with &lt;code&gt;\\&quot;text\\&quot;&lt;/code&gt; as the &lt;code&gt;question&lt;/code&gt; and &lt;code&gt;\\&quot;text_pair\\&quot;&lt;/code&gt; as the &lt;code&gt;passage&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,7,&quot;randomNumber&quot;,0.0926165734285449,&quot;assignment&quot;,&quot;&lt;p&gt;A content moderation team in a large tech company needs to automatically validate whether a passage from a knowledge base answers a customer query. They want to speed up the process using a pre-trained QNLI model to assess the relevance of each response. Your goal is to implement a solution that can classify whether a given passage contains the answer to a specific question.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;sample_codes&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;difficulty&quot;,0,&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the QNLI pipeline\\nclassifier = ____\\n\\npassage = \\&quot;Our refund policy allows customers to return any item within 30 days of purchase, provided the item is in its original condition and accompanied by the receipt. Refunds are issued to the original payment method within 5–7 business days.\\&quot;\\nquestion = \\&quot;Can I get a refund if I return a product after 20 days?\\&quot;\\n\\n# Get the result\\nresult = ____\\nprint(result)&quot;]]]],&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Does the text answer the question?&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;solution&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the QNLI pipeline\\nclassifier = pipeline(task=\\&quot;text-classification\\&quot;, model=\\&quot;cross-encoder/qnli-electra-base\\&quot;)\\n\\npassage = \\&quot;Our refund policy allows customers to return any item within 30 days of purchase, provided the item is in its original condition and accompanied by the receipt. Refunds are issued to the original payment method within 5–7 business days.\\&quot;\\nquestion = \\&quot;Can I get a refund if I return a product after 20 days?\\&quot;\\n\\n# Get the result\\nresult = classifier({\\n    \\&quot;text\\&quot;: question,\\n    \\&quot;text_pair\\&quot;: passage\\n})\\nprint(result)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,1918992,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,1918993,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,&quot;learn-heavy&quot;,&quot;number&quot;,8,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.2609561184083786,&quot;chapter_id&quot;,133925,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;Question similarity and grammatical correctness&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,1918993,&quot;projector_key&quot;,&quot;course_41242_4a3531e4ba5bcfe11ee135ca20231603&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;d87cc29db8&quot;,&quot;course_id&quot;,41242]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = ____(task=\\&quot;____\\&quot;, model=\\&quot;____\\&quot;)\\n\\nquestion_1 = \\&quot;What&#39;s the process to change my password?\\&quot;\\nquestion_2 = \\&quot;How do I reset my account password?\\&quot;\\n\\n# Detect if the two questions are paraphrases\\nresult = classifier({\\n    \\&quot;____\\&quot;: ____,\\n    \\&quot;____\\&quot;: ____\\n})\\n\\nprint(result)&quot;,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;question_1\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `question_1` variable.\\&quot;),\\n  check_object(\\&quot;question_2\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `question_2` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\n  check_or(\\n    has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question_1\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question_1` as the value for the `&#39;text&#39;` key in the classifier?\\&quot;),\\n    has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question_2\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question_1` as the value for the `&#39;text&#39;` key in the classifier?\\&quot;),\\n  ),\\n  check_or(\\n    has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text_pair(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question_1\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question_2` as the value for the `&#39;text_pair&#39;` key in the classifier?\\&quot;),\\n    has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text_pair(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question_2\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question_2` as the value for the `&#39;text_pair&#39;` key in the classifier?\\&quot;),\\n  ),\\n  check_function(&#39;print&#39;).check_args(0).has_equal_value(incorrect_msg=\\&quot;Did you print the `result` variable?\\&quot;)\\n)\\n\\nsuccess_msg(\\&quot;Great work! The QQP model detected that these questions are 57% similar! This helps reduce duplicate content on the support forum, streamlining search results and ensuring users quickly find accurate answers, boosting efficiency for both users and support staff.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a suitable &lt;code&gt;classifier&lt;/code&gt; pipeline with the &lt;code&gt;\\&quot;textattack/bert-base-uncased-QQP\\&quot;&lt;/code&gt; model.&lt;/li&gt;\\n&lt;li&gt;Use the pipeline to classify whether &lt;code&gt;question_1&lt;/code&gt; and &lt;code&gt;question_2&lt;/code&gt; are paraphrases.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,1918994,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;To detect if two questions are paraphrases, we need a &lt;code&gt;text-classification&lt;/code&gt; task when defining the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;li&gt;Pass the questions as a dictionary with &lt;code&gt;\\&quot;text\\&quot;&lt;/code&gt; and &lt;code&gt;\\&quot;text_pair\\&quot;&lt;/code&gt; keys to the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,9,&quot;randomNumber&quot;,0.27559627032120115,&quot;assignment&quot;,&quot;&lt;p&gt;A startup is developing a Q&amp;amp;A assistant to improve the user experience on their support forum. One key feature is to detect when users ask the same question using different words. You&#39;ve been asked to implement a solution using a pre-trained QQP model that can determine whether two questions are duplicates.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;sample_codes&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;difficulty&quot;,0,&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = ____(task=\\&quot;____\\&quot;, model=\\&quot;____\\&quot;)\\n\\nquestion_1 = \\&quot;What&#39;s the process to change my password?\\&quot;\\nquestion_2 = \\&quot;How do I reset my account password?\\&quot;\\n\\n# Detect if the two questions are paraphrases\\nresult = classifier({\\n    \\&quot;____\\&quot;: ____,\\n    \\&quot;____\\&quot;: ____\\n})\\n\\nprint(result)&quot;]]]],&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Detecting duplicate questions&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;solution&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = pipeline(task=\\&quot;text-classification\\&quot;, model=\\&quot;textattack/distilbert-base-uncased-QQP\\&quot;)\\n\\nquestion_1 = \\&quot;What&#39;s the process to change my password?\\&quot;\\nquestion_2 = \\&quot;How do I reset my account password?\\&quot;\\n\\n# Detect if the two questions are paraphrases\\nresult = classifier({\\n    \\&quot;text\\&quot;: question_1,\\n    \\&quot;text_pair\\&quot;: question_2\\n})\\n\\nprint(result)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,1918994,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = ____\\n\\nuser_text = \\&quot;Although she was knowing the answer, she didn&#39;t raised her hand during the class discussion.\\&quot;\\n\\n# Classify grammatical acceptability\\nresult = ____\\n\\nprint(result)&quot;,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;user_text\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `user_text` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\n  check_function(&#39;print&#39;).check_args(0).has_equal_value(incorrect_msg=\\&quot;Did you print the `result` variable?\\&quot;)\\n)\\n\\nsuccess_msg(\\&quot;Well done! The model found the sentence to be 78% acceptable. This feature will power instant grammar feedback in the educational app, helping users improve their writing skills and build stronger language habits over time.\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a &lt;code&gt;classifier&lt;/code&gt; pipeline with the &lt;code&gt;\\&quot;textattack/bert-base-uncased-CoLA\\&quot;&lt;/code&gt; model.&lt;/li&gt;\\n&lt;li&gt;Use the pipeline to check if the &lt;code&gt;user_text&lt;/code&gt; is grammatically acceptable.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,1918995,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use the &lt;code&gt;\\&quot;text-classification\\&quot;&lt;/code&gt; task when creating the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;li&gt;Pass the sentence directly to the pipeline to classify its grammaticality.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,10,&quot;randomNumber&quot;,0.10163630465043383,&quot;assignment&quot;,&quot;&lt;p&gt;An educational app is being built to help users improve their grammar. One core feature automatically checks whether user-submitted sentences are grammatically acceptable. You&#39;ve been asked to implement this feature using a model trained on the Corpus of Linguistic Acceptability (CoLA) to classify sentence correctness.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;sample_codes&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;difficulty&quot;,0,&quot;sample_code&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = ____\\n\\nuser_text = \\&quot;Although she was knowing the answer, she didn&#39;t raised her hand during the class discussion.\\&quot;\\n\\n# Classify grammatical acceptability\\nresult = ____\\n\\nprint(result)&quot;]]]],&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Checking grammatical correctness&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;import warnings\\nwarnings.filterwarnings(\\&quot;ignore\\&quot;)\\nfrom transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;solution&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = pipeline(task=\\&quot;text-classification\\&quot;, model=\\&quot;textattack/bert-base-uncased-CoLA\\&quot;)\\n\\nuser_text = \\&quot;Although she was knowing the answer, she didn&#39;t raised her hand during the class discussion.\\&quot;\\n\\n# Classify grammatical acceptability\\nresult = classifier(user_text)\\n\\nprint(result)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,1918995,&quot;programming_language&quot;,null]]]],&quot;canRateChapter&quot;,false,&quot;isChapterCompleted&quot;,false]],&quot;learningMode&quot;,&quot;course&quot;,&quot;learningRecap&quot;,[&quot;^ &quot;,&quot;readyToShow&quot;,false,&quot;recap&quot;,null],&quot;location&quot;,[&quot;^?&quot;,[&quot;current&quot;,[&quot;^?&quot;,[&quot;pathname&quot;,&quot;/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face&quot;,&quot;query&quot;,[&quot;^?&quot;,[&quot;ex&quot;,&quot;2&quot;]]]],&quot;language&quot;,&quot;en&quot;,&quot;canonical&quot;,null]],&quot;mobilePopup&quot;,[&quot;^?&quot;,[]],&quot;onboardingMilestones&quot;,[&quot;^ &quot;,&quot;isStarted&quot;,false,&quot;isActive&quot;,true,&quot;step&quot;,0],&quot;notes&quot;,[&quot;^ &quot;,&quot;workspaceNotes&quot;,null,&quot;workspaceTemplate&quot;,[&quot;^ &quot;,&quot;_tag&quot;,&quot;course&quot;,&quot;courseId&quot;,41242,&quot;title&quot;,&quot;Course Notes: Natural Language Processing (NLP) in Python&quot;]],&quot;output&quot;,[&quot;^ &quot;,&quot;lastErrorMessage&quot;,null,&quot;^W&quot;,[]],&quot;lessons&quot;,[[&quot;^ &quot;,&quot;chapterId&quot;,133923,&quot;chapterNumber&quot;,1,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888943,&quot;number&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1903567,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1903568,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1903570,&quot;^10&quot;,2,&quot;subexercises&quot;,[[&quot;^ &quot;,&quot;id&quot;,1903571,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1903572,&quot;^10&quot;,2]]],[&quot;^ &quot;,&quot;id&quot;,1903569,&quot;^10&quot;,3]],&quot;id&quot;,111824,&quot;^10&quot;,1,&quot;^V&quot;,&quot;Introduction to natural language processing&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133923,&quot;^[&quot;,1,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1908634,&quot;^10&quot;,4],[&quot;^ &quot;,&quot;id&quot;,1908635,&quot;^10&quot;,5],[&quot;^ &quot;,&quot;id&quot;,1908636,&quot;^10&quot;,6]],&quot;id&quot;,116314,&quot;^10&quot;,2,&quot;^V&quot;,&quot;Stop words and punctuation handling&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133923,&quot;^[&quot;,1,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1908637,&quot;^10&quot;,7],[&quot;^ &quot;,&quot;id&quot;,1908638,&quot;^10&quot;,8,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1908639,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1908640,&quot;^10&quot;,2]]],[&quot;^ &quot;,&quot;id&quot;,1914343,&quot;^10&quot;,8],[&quot;^ &quot;,&quot;id&quot;,1914344,&quot;^10&quot;,9],[&quot;^ &quot;,&quot;id&quot;,1908641,&quot;^10&quot;,10]],&quot;id&quot;,116315,&quot;^10&quot;,3,&quot;^V&quot;,&quot;Text normalization techniques&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133924,&quot;^[&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911685,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1888944,&quot;^10&quot;,1,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888945,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1888946,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1888947,&quot;^10&quot;,3]]],[&quot;^ &quot;,&quot;id&quot;,1911686,&quot;^10&quot;,2,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911687,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911688,&quot;^10&quot;,2]]],[&quot;^ &quot;,&quot;id&quot;,1914345,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1914346,&quot;^10&quot;,3],[&quot;^ &quot;,&quot;id&quot;,1911689,&quot;^10&quot;,4,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911690,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911691,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911692,&quot;^10&quot;,2]]],[&quot;^ &quot;,&quot;id&quot;,1945422,&quot;^10&quot;,5]],&quot;id&quot;,111825,&quot;^10&quot;,1,&quot;^V&quot;,&quot;Bag-of-Words representation&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133924,&quot;^[&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911693,&quot;^10&quot;,6],[&quot;^ &quot;,&quot;id&quot;,1911694,&quot;^10&quot;,7],[&quot;^ &quot;,&quot;id&quot;,1911695,&quot;^10&quot;,8,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911696,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911697,&quot;^10&quot;,2]]]],&quot;id&quot;,115123,&quot;^10&quot;,2,&quot;^V&quot;,&quot;TF-IDF vectorization&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133924,&quot;^[&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1903573,&quot;^10&quot;,9],[&quot;^ &quot;,&quot;id&quot;,1911698,&quot;^10&quot;,10],[&quot;^ &quot;,&quot;id&quot;,1911699,&quot;^10&quot;,11,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911700,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911701,&quot;^10&quot;,2]]]],&quot;id&quot;,117071,&quot;^10&quot;,3,&quot;^V&quot;,&quot;Embeddings&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133925,&quot;^[&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888948,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1918984,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1918985,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1918986,&quot;^10&quot;,3],[&quot;^ &quot;,&quot;id&quot;,1918987,&quot;^10&quot;,4,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1918988,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1918989,&quot;^10&quot;,2]]]],&quot;id&quot;,111826,&quot;^10&quot;,1,&quot;^V&quot;,&quot;Hugging Face pipelines for sentiment analysis&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133925,&quot;^[&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1918990,&quot;^10&quot;,5],[&quot;^ &quot;,&quot;id&quot;,1918991,&quot;^10&quot;,6],[&quot;^ &quot;,&quot;id&quot;,1918992,&quot;^10&quot;,7]],&quot;id&quot;,118738,&quot;^10&quot;,2,&quot;^V&quot;,&quot;Zero-shot classification and QNLI&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133925,&quot;^[&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1918993,&quot;^10&quot;,8],[&quot;^ &quot;,&quot;id&quot;,1918994,&quot;^10&quot;,9],[&quot;^ &quot;,&quot;id&quot;,1918995,&quot;^10&quot;,10]],&quot;id&quot;,118739,&quot;^10&quot;,3,&quot;^V&quot;,&quot;Question similarity and grammatical correctness&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133926,&quot;^[&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888949,&quot;^10&quot;,1,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888950,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1888951,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1888952,&quot;^10&quot;,3],[&quot;^ &quot;,&quot;id&quot;,1888953,&quot;^10&quot;,4]]],[&quot;^ &quot;,&quot;id&quot;,1927536,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1927537,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1927538,&quot;^10&quot;,3]],&quot;id&quot;,111827,&quot;^10&quot;,1,&quot;^V&quot;,&quot;Token classification&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133926,&quot;^[&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1927539,&quot;^10&quot;,4],[&quot;^ &quot;,&quot;id&quot;,1927540,&quot;^10&quot;,5],[&quot;^ &quot;,&quot;id&quot;,1927541,&quot;^10&quot;,6]],&quot;id&quot;,120731,&quot;^10&quot;,2,&quot;^V&quot;,&quot;Question answering&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133926,&quot;^[&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1927542,&quot;^10&quot;,7],[&quot;^ &quot;,&quot;id&quot;,1927543,&quot;^10&quot;,8],[&quot;^ &quot;,&quot;id&quot;,1927544,&quot;^10&quot;,9],[&quot;^ &quot;,&quot;id&quot;,1927545,&quot;^10&quot;,10]],&quot;id&quot;,120732,&quot;^10&quot;,3,&quot;^V&quot;,&quot;Sequence generation tasks&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133926,&quot;^[&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1927546,&quot;^10&quot;,11]],&quot;id&quot;,120733,&quot;^10&quot;,4,&quot;^V&quot;,&quot;Congratulations&quot;]],&quot;preFetchedData&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedDataStateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^&gt;&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;data&quot;,[&quot;^ &quot;,&quot;id&quot;,133925,&quot;title_meta&quot;,null,&quot;^V&quot;,&quot;Text Classification with Hugging Face&quot;,&quot;description&quot;,&quot;Harness the power of pre-trained models to perform advanced text classification tasks. Use Hugging Face pipelines for sentiment analysis, topic classification, and natural language inference. Evaluate semantic similarity and grammatical correctness with state-of-the-art models, all without building anything from scratch.&quot;,&quot;^10&quot;,3,&quot;slug&quot;,&quot;text-classification-with-hugging-face&quot;,&quot;nb_exercises&quot;,10,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;last_updated_on&quot;,&quot;08/07/2025&quot;,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter3.pdf&quot;,&quot;free_preview&quot;,null,&quot;xp&quot;,850,&quot;number_of_videos&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Hugging Face pipelines for sentiment analysis&quot;,&quot;aggregate_xp&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Analyzing the sentiment of a review&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Batch classifying multiple reviews&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=3&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;TabExercise&quot;,&quot;^V&quot;,&quot;Comparing models on labeled review data&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=4&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Zero-shot classification and QNLI&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=5&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Zero-shot classification of support tickets&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=6&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Does the text answer the question?&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=7&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Question similarity and grammatical correctness&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=8&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Detecting duplicate questions&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=9&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Checking grammatical correctness&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=10&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null]]]]]],&quot;^E&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^13&quot;,[&quot;^ &quot;,&quot;id&quot;,41242,&quot;^V&quot;,&quot;Natural Language Processing (NLP) in Python&quot;,&quot;^15&quot;,&quot;Unlock the power of Natural Language Processing (NLP) and take your text analysis skills to the next level! This course equips you with essential tools to process, analyze, and extract insights from text data. Start with the fundamentals of text processing, such as tokenization, lemmatization, and stemming, to extracting meaningful numerical features from text using bag-of-words (BoW), TF-IDF, and embeddings. Finally, harness the power of state-of-the-art transformer models using Hugging Face. Perform sentiment analysis, classify content, analyze question-answer relationships, assess grammatical acceptability, and generate text using the latest models.&quot;,&quot;short_description&quot;,&quot;Master text analysis with essential NLP techniques from preprocessing to advanced transformer models. &quot;,&quot;author_field&quot;,null,&quot;author_bio&quot;,null,&quot;author_image&quot;,&quot;placeholder.png&quot;,&quot;nb_of_subscriptions&quot;,2119,&quot;^16&quot;,&quot;natural-language-processing-nlp-in-python&quot;,&quot;image_url&quot;,&quot;https://assets.datacamp.com/production/default/shields/placeholder.png&quot;,&quot;image_thumbnail_url&quot;,&quot;https://assets.datacamp.com/production/default/shields/placeholder.png&quot;,&quot;^1:&quot;,&quot;07/10/2025&quot;,&quot;link&quot;,&quot;https://www.datacamp.com/courses/natural-language-processing-nlp-in-python&quot;,&quot;should_cache&quot;,true,&quot;^B&quot;,&quot;datacamp&quot;,&quot;difficulty_level&quot;,2,&quot;state&quot;,&quot;live&quot;,&quot;university&quot;,null,&quot;sharing_links&quot;,[&quot;^ &quot;,&quot;twitter&quot;,&quot;http://bit.ly/1eWTMJh&quot;,&quot;facebook&quot;,&quot;http://bit.ly/1iS42Do&quot;],&quot;marketing_video&quot;,&quot;&quot;,&quot;^1@&quot;,&quot;python&quot;,&quot;paid&quot;,true,&quot;xp&quot;,3550,&quot;topic_id&quot;,16,&quot;technology_id&quot;,2,&quot;reduced_outline&quot;,null,&quot;^1A&quot;,&quot;learn-heavy&quot;,&quot;lti_only&quot;,false,&quot;instructors&quot;,[[&quot;^ &quot;,&quot;id&quot;,10350864,&quot;marketing_biography&quot;,&quot;Machine Learning Engineer&quot;,&quot;biography&quot;,&quot;Fouad is an experienced ML engineer, researcher, and educator, currently pursuing a Ph.D. in applied ML, with a focus on cybersecurity applications. His talent lies in simplifying complex data science concepts, making them accessible to everyone.&quot;,&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/003/004/square/1683950699469.jpg?1705586868&quot;,&quot;full_name&quot;,&quot;Fouad Trad&quot;,&quot;instructor_path&quot;,&quot;/instructors/fat10&quot;]],&quot;collaborators&quot;,[[&quot;^ &quot;,&quot;^1Z&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/002/582/square/20210323_102554_small2.jpg?1705586726&quot;,&quot;^1[&quot;,&quot;James Chapman&quot;],[&quot;^ &quot;,&quot;^1Z&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/002/714/square/myprofilephoto.jpeg?1705586799&quot;,&quot;^1[&quot;,&quot;Jasmin Ludolf&quot;],[&quot;^ &quot;,&quot;^1Z&quot;,&quot;https://assets.datacamp.com/users/avatars/014/780/775/square/%D0%9E%D0%B1%D1%8C%D1%8F%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%9A%D0%BE%D0%BD%D0%BA%D0%B8%D0%BD_%281%29.jpg?1711368550&quot;,&quot;^1[&quot;,&quot;Stan Konkin&quot;]],&quot;datasets&quot;,[[&quot;^ &quot;,&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/7025/datasets/b3f14ad8963bf73caf65e0f5ae4eab5bdc123f63/product_reviews.csv&quot;,&quot;name&quot;,&quot;product_reviews.csv&quot;]],&quot;tracks&quot;,[],&quot;prerequisites&quot;,[[&quot;^ &quot;,&quot;path&quot;,&quot;/courses/python-toolbox&quot;,&quot;^V&quot;,&quot;Python Toolbox&quot;]],&quot;time_needed_in_hours&quot;,4,&quot;seo_title&quot;,&quot;Natural Language Processing (NLP) in Python&quot;,&quot;seo_description&quot;,&quot;Master text analysis with essential NLP techniques from preprocessing to advanced transformer models. &quot;,&quot;archived_at&quot;,null,&quot;original_image_url&quot;,&quot;https://assets.datacamp.com/production/default/shields/placeholder.png&quot;,&quot;external_slug&quot;,&quot;natural-language-processing-nlp-in-python&quot;,&quot;mobile_enabled&quot;,true,&quot;case_study&quot;,false,&quot;difficulty_level_hardcoded&quot;,true,&quot;long_description&quot;,&quot;&lt;h2&gt;Build a Strong NLP Foundation &lt;/h2&gt;Unlock the power of Natural Language Processing (NLP) and take your text analysis skills to the next level! This course equips you with essential tools to process, analyze, and extract insights from text data. Start with the fundamentals of text processing, from tokenization to cleaning and normalizing text by removing stop words, punctuation, and applying lemmatization and stemming to improve text consistency.&lt;br&gt;&lt;br&gt;&lt;h2&gt;Extract Meaningful Features from Text&lt;/h2&gt;Go beyond raw text and transform it into numerical representations! Explore the Bag-of-Words representation, dive into TF-IDF vectorization, and leverage powerful word embeddings like Word2Vec and GloVe to capture semantic relationships between words.&lt;br&gt;&lt;br&gt;&lt;h2&gt;Classify and Generate Text with AI&lt;/h2&gt;Harness the power of state-of-the-art transformer models using Hugging Face pipelines. Learn how to perform sentiment analysis, classify content, analyze question-answer relationships, assess grammatical acceptability, and generate text using various models. Explore Named Entity Recognition (NER), Part-of-Speech (PoS) tagging, text summarization, and translation to expand your NLP toolkit.&lt;br&gt;&lt;br&gt;&lt;h2&gt;Master key NLP libraries&lt;/h2&gt;By the end of this course, you’ll have a strong grasp of NLP fundamentals and hands-on experience with key libraries such as nltk, sklearn, gensim, and Hugging Face’s transformers. Start your journey today and transform the way you interact with text data!&quot;,&quot;industry_ids&quot;,[],&quot;audio_recorders&quot;,[],&quot;content_area&quot;,&quot;Data Science and Analytics&quot;,&quot;is_labeled_as_new&quot;,false,&quot;tier&quot;,2,&quot;private&quot;,false,&quot;private_access&quot;,[&quot;^ &quot;],&quot;hide_openai_branding&quot;,true,&quot;content_updated_at&quot;,&quot;2025-07-08T09:25:45Z&quot;,&quot;learning_objectives&quot;,[],&quot;cpe_credits&quot;,null,&quot;duration_minutes&quot;,240,&quot;content_branding&quot;,&quot;DataCamp&quot;,&quot;has_variant_traditional&quot;,true,&quot;has_variant_ai_native&quot;,false,&quot;chapters&quot;,[[&quot;^ &quot;,&quot;id&quot;,133923,&quot;^14&quot;,null,&quot;^V&quot;,&quot;Text Processing Fundamentals&quot;,&quot;^15&quot;,&quot;Learn the essentials of text processing in Natural Language Processing (NLP). Master techniques such as tokenization, stop word and punctuation removal, and text normalization with lowercasing, stemming, and lemmatization to prepare text data for further analysis and insight extraction.&quot;,&quot;^10&quot;,1,&quot;^16&quot;,&quot;text-processing-fundamentals&quot;,&quot;^17&quot;,10,&quot;^18&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^19&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1:&quot;,&quot;08/07/2025&quot;,&quot;^1;&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter1.pdf&quot;,&quot;^1&lt;&quot;,true,&quot;xp&quot;,850,&quot;^1=&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Introduction to natural language processing&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;TabExercise&quot;,&quot;^V&quot;,&quot;Sentence and word tokenization&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;DragAndDropExercise&quot;,&quot;^V&quot;,&quot;NLP workflow&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=3&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Stop words and punctuation handling&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=4&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Removing stop words&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=5&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Removing punctuation&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=6&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Text normalization techniques&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=7&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Lowercasing&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=8&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Stemming&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=9&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Lemmatization&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-processing-fundamentals?ex=10&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null]]],[&quot;^ &quot;,&quot;id&quot;,133924,&quot;^14&quot;,null,&quot;^V&quot;,&quot;Feature Extraction from Text&quot;,&quot;^15&quot;,&quot;Transform raw text into powerful numerical features. Create Bag-of-Words and TF-IDF representations to capture word importance across documents, then explore word embeddings like Word2Vec and GloVe to uncover deep semantic patterns. Visualize frequency, relevance, and similarity to bring your text data to life.&quot;,&quot;^10&quot;,2,&quot;^16&quot;,&quot;feature-extraction-from-text&quot;,&quot;^17&quot;,11,&quot;^18&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^19&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1:&quot;,&quot;08/07/2025&quot;,&quot;^1;&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter2.pdf&quot;,&quot;^1&lt;&quot;,null,&quot;xp&quot;,950,&quot;^1=&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Bag-of-Words representation&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Building vocabulary from customer reviews&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Transforming text to numbers with BoW&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=3&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;TabExercise&quot;,&quot;^V&quot;,&quot;Frequency analysis of product reviews&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=4&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Visualizing word frequencies&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=5&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;TF-IDF vectorization&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=6&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;TF-IDF representation of product feedback&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=7&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;BulletExercise&quot;,&quot;^V&quot;,&quot;Comparing BoW and TF-IDF representations&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=8&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Embeddings&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=9&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Exploring word relationships with embeddings&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=10&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;BulletExercise&quot;,&quot;^V&quot;,&quot;Visualizing and comparing word embeddings&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/feature-extraction-from-text?ex=11&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null]]],[&quot;^ &quot;,&quot;id&quot;,133925,&quot;^14&quot;,null,&quot;^V&quot;,&quot;Text Classification with Hugging Face&quot;,&quot;^15&quot;,&quot;Harness the power of pre-trained models to perform advanced text classification tasks. Use Hugging Face pipelines for sentiment analysis, topic classification, and natural language inference. Evaluate semantic similarity and grammatical correctness with state-of-the-art models, all without building anything from scratch.&quot;,&quot;^10&quot;,3,&quot;^16&quot;,&quot;text-classification-with-hugging-face&quot;,&quot;^17&quot;,10,&quot;^18&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^19&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1:&quot;,&quot;08/07/2025&quot;,&quot;^1;&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter3.pdf&quot;,&quot;^1&lt;&quot;,null,&quot;xp&quot;,850,&quot;^1=&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Hugging Face pipelines for sentiment analysis&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Analyzing the sentiment of a review&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,null,&quot;^1&gt;&quot;,50,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Batch classifying multiple reviews&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=3&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;TabExercise&quot;,&quot;^V&quot;,&quot;Comparing models on labeled review data&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=4&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Zero-shot classification and QNLI&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=5&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Zero-shot classification of support tickets&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=6&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Does the text answer the question?&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=7&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Question similarity and grammatical correctness&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=8&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Detecting duplicate questions&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=9&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Checking grammatical correctness&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/text-classification-with-hugging-face?ex=10&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null]]],[&quot;^ &quot;,&quot;id&quot;,133926,&quot;^14&quot;,null,&quot;^V&quot;,&quot;Token Classification and Text Generation&quot;,&quot;^15&quot;,&quot;Dive into the core of modern NLP applications with token classification and text generation techniques. Learn to extract meaningful entities and grammatical structures using NER and PoS tagging. Master both extractive and abstractive question answering, and explore advanced generation tasks including summarization, translation, and language modeling using Hugging Face pipelines.&quot;,&quot;^10&quot;,4,&quot;^16&quot;,&quot;token-classification-and-text-generation&quot;,&quot;^17&quot;,11,&quot;^18&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^19&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1:&quot;,&quot;08/07/2025&quot;,&quot;^1;&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/41242/chapter4.pdf&quot;,&quot;^1&lt;&quot;,null,&quot;xp&quot;,900,&quot;^1=&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Token classification&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=1&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Identifying named entities in news headlines&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=2&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Part of Speech tagging for text analysis&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=3&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Question answering&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=4&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Answering questions from product descriptions&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=5&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Generating natural answers with abstractive QA&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=6&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Sequence generation tasks&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=7&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Summarizing news articles for quick insights&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=8&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Translating customer reviews to French&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=9&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^V&quot;,&quot;Building a search completion system&quot;,&quot;^1&gt;&quot;,100,&quot;^10&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=10&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^V&quot;,&quot;Congratulations&quot;,&quot;^1&gt;&quot;,50,&quot;^10&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/natural-language-processing-nlp-in-python/token-classification-and-text-generation?ex=11&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null]]]],&quot;course_resources&quot;,[],&quot;translated_course_id&quot;,41242,&quot;restricted&quot;,false,&quot;restricted_reasons&quot;,[]]]]],&quot;^F&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^13&quot;,[[&quot;^ &quot;,&quot;id&quot;,1918984,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;assignment&quot;,null,&quot;^V&quot;,&quot;Hugging Face pipelines for sentiment analysis&quot;,&quot;sample_code&quot;,&quot;&quot;,&quot;instructions&quot;,null,&quot;^10&quot;,1,&quot;sct&quot;,&quot;&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;attachments&quot;,null,&quot;xp&quot;,50,&quot;possible_answers&quot;,[],&quot;feedbacks&quot;,[],&quot;question&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,&quot;learn-heavy&quot;,&quot;video_link&quot;,null,&quot;video_hls&quot;,null,&quot;aspect_ratio&quot;,56.25,&quot;projector_key&quot;,&quot;course_41242_087144e37d58af08ee7becba96827870&quot;,&quot;key&quot;,&quot;046569f077&quot;,&quot;language&quot;,&quot;python&quot;,&quot;course_id&quot;,41242,&quot;chapter_id&quot;,133925,&quot;version&quot;,&quot;v0&quot;,&quot;randomNumber&quot;,0.35910499165883913,&quot;externalId&quot;,1918984],[&quot;^ &quot;,&quot;id&quot;,1918985,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2V&quot;,&quot;&lt;p&gt;Your team is building a tool to monitor customer sentiment in product reviews. As a first step, you&#39;re testing the sentiment of individual reviews using a pre-trained pipeline.&lt;/p&gt;&quot;,&quot;^V&quot;,&quot;Analyzing the sentiment of a review&quot;,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Define the sentiment analysis pipeline\\nclassifier = ____\\n\\nreview_text = \\&quot;The new update made the app much faster and easier to use!\\&quot;\\n\\n# Get sentiment prediction\\nresult = ____\\n\\nprint(result)&quot;,&quot;^2X&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a &lt;code&gt;pipeline&lt;/code&gt; for &lt;code&gt;sentiment-analysis&lt;/code&gt; with the &lt;code&gt;\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;&lt;/code&gt; model.&lt;/li&gt;\\n&lt;li&gt;Use the &lt;code&gt;pipeline&lt;/code&gt; to classify the sentiment of &lt;code&gt;review_text&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^10&quot;,2,&quot;sct&quot;,&quot;# Examples of good success messages: https://instructor-support.datacamp.com/en/articles/2299773-exercise-success-messages.\\n\\nsig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n  check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n  check_object(\\&quot;review_text\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n  check_function(&#39;print&#39;).check_args(0).has_equal_value(incorrect_msg=\\&quot;Did you print the `result` variable?\\&quot;)\\n) \\n\\nsuccess_msg(\\&quot;Well done! You&#39;ve classified a single review. Let’s scale this to multiple reviews next.\\&quot;)&quot;,&quot;^2Y&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;^2Z&quot;,&quot;from transformers import pipeline\\n\\n# Define the sentiment analysis pipeline\\nclassifier = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\n\\nreview_text = \\&quot;The new update made the app much faster and easier to use!\\&quot;\\n\\n# Get sentiment prediction\\nresult = classifier(review_text)\\n\\nprint(result)&quot;,&quot;^2[&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;A &lt;code&gt;pipeline&lt;/code&gt; takes two arguments: &lt;code&gt;task&lt;/code&gt; and &lt;code&gt;model&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;To classify the sentiment of a &lt;code&gt;review_text&lt;/code&gt;, pass it directly into the &lt;code&gt;pipeline&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^30&quot;,null,&quot;xp&quot;,100,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;sample_codes&quot;,[[&quot;^ &quot;,&quot;difficulty&quot;,0,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Define the sentiment analysis pipeline\\nclassifier = ____\\n\\nreview_text = \\&quot;The new update made the app much faster and easier to use!\\&quot;\\n\\n# Get sentiment prediction\\nresult = ____\\n\\nprint(result)&quot;]],&quot;^38&quot;,&quot;python&quot;,&quot;^3&lt;&quot;,0.25550630139871777,&quot;^3=&quot;,1918985],[&quot;^ &quot;,&quot;id&quot;,1918986,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2V&quot;,&quot;&lt;p&gt;Your sentiment analysis pipeline works well on one review. Now it&#39;s time to handle multiple reviews in one batch. This is a key step before analyzing user feedback at scale.&lt;/p&gt;&quot;,&quot;^V&quot;,&quot;Batch classifying multiple reviews&quot;,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\nclassifier = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\n\\nreview_batch = [\\n    \\&quot;Absolutely love the new design!\\&quot;,\\n    \\&quot;The app crashes every time I open it.\\&quot;,\\n    \\&quot;Customer support was helpful and quick.\\&quot;,\\n    \\&quot;Too many ads make it unusable.\\&quot;,\\n    \\&quot;Everything works fine, but it’s a bit slow.\\&quot;\\n]\\n\\n# Classify sentiments\\nresults = ____\\nprint(results)&quot;,&quot;^2X&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a &lt;code&gt;pipeline&lt;/code&gt; for &lt;code&gt;sentiment-analysis&lt;/code&gt; using &lt;code&gt;\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use the &lt;code&gt;pipeline&lt;/code&gt; to classify all reviews in the &lt;code&gt;review_batch&lt;/code&gt; list.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^10&quot;,3,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;review_batch\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `review_batch` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n  check_function(&#39;print&#39;).check_args(0).has_equal_value(incorrect_msg=\\&quot;Did you print the `result` variable?\\&quot;)\\n) \\nsuccess_msg(\\&quot;Nice! You&#39;ve classified a batch of reviews. Now let&#39;s compare how two different models perform on the same dataset.\\&quot;)&quot;,&quot;^2Y&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;^2Z&quot;,&quot;from transformers import pipeline\\n\\nclassifier = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\n\\nreview_batch = [\\n    \\&quot;Absolutely love the new design!\\&quot;,\\n    \\&quot;The app crashes every time I open it.\\&quot;,\\n    \\&quot;Customer support was helpful and quick.\\&quot;,\\n    \\&quot;Too many ads make it unusable.\\&quot;,\\n    \\&quot;Everything works fine, but it’s a bit slow.\\&quot;\\n]\\n\\n# Classify sentiments\\nresults = classifier(review_batch)\\nprint(results)&quot;,&quot;^2[&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;The pipeline can accept a list of strings to return a list of results.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^30&quot;,null,&quot;xp&quot;,100,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;^3&gt;&quot;,[[&quot;^ &quot;,&quot;^3?&quot;,0,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\nclassifier = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\n\\nreview_batch = [\\n    \\&quot;Absolutely love the new design!\\&quot;,\\n    \\&quot;The app crashes every time I open it.\\&quot;,\\n    \\&quot;Customer support was helpful and quick.\\&quot;,\\n    \\&quot;Too many ads make it unusable.\\&quot;,\\n    \\&quot;Everything works fine, but it’s a bit slow.\\&quot;\\n]\\n\\n# Classify sentiments\\nresults = ____\\nprint(results)&quot;]],&quot;^38&quot;,&quot;python&quot;,&quot;^3&lt;&quot;,0.20526280162907096,&quot;^3=&quot;,1918986],[&quot;^ &quot;,&quot;id&quot;,1918987,&quot;^B&quot;,&quot;TabExercise&quot;,&quot;^2V&quot;,&quot;&lt;p&gt;Now that you can classify sentiment in bulk, your team wants to evaluate which model is more reliable. You&#39;ll compare two models using a larger labeled dataset of reviews and measure their accuracy.&lt;/p&gt;\\n&lt;p&gt;A &lt;code&gt;texts&lt;/code&gt; list and its &lt;code&gt;true_labels&lt;/code&gt; are pre-loaded for you.&lt;/p&gt;&quot;,&quot;^V&quot;,&quot;Comparing models on labeled review data&quot;,&quot;^2W&quot;,&quot;&quot;,&quot;^2X&quot;,null,&quot;^10&quot;,4,&quot;sct&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;texts = [\\n    \\&quot;I can&#39;t believe how great this app is, it’s honestly a game-changer!\\&quot;,       \\n    \\&quot;It’s not as bad as I expected, but still not great.\\&quot;,                     \\n    \\&quot;The update did fix a lot of issues, so I’m glad they listened to feedback.\\&quot;,\\n    \\&quot;It’s just another buggy version with more problems than before.\\&quot;,        \\n    \\&quot;I&#39;m amazed by how quickly it works now, truly impressed.\\&quot;,                \\n    \\&quot;Oh look, the app works for once. Not sure if it&#39;s a fluke or progress.\\&quot;,  \\n    \\&quot;The new design is a pleasant surprise — I didn&#39;t expect it to be this good.\\&quot;, \\n    \\&quot;The app keeps freezing when I need it most. Terrible experience.\\&quot;,        \\n    \\&quot;I didn’t think it was possible, but this update made things even worse.\\&quot;,  \\n    \\&quot;Wow, finally an update that makes sense. So happy about this!\\&quot;,           \\n    \\&quot;At least the app doesn’t crash every five minutes now. That’s something.\\&quot;, \\n    \\&quot;I’ve never been so impressed by an app’s performance. Outstanding!\\&quot;,      \\n    \\&quot;I’m sure it works for some people, but not for me. A lot of problems.\\&quot;,    \\n    \\&quot;It’s almost like the developers actually care now. Big improvement!\\&quot;,     \\n    \\&quot;The app is still the same: slow, frustrating, and useless.\\&quot;,              \\n    \\&quot;The new features are cool, but the app is still very glitchy.\\&quot;,         \\n    \\&quot;I wish I had known about this app sooner, it really does make a difference.\\&quot;,\\n    \\&quot;I regret wasting my time on this app. I’ve had enough.\\&quot;,                 \\n    \\&quot;I’m so happy they fixed that bug, I didn’t realize how much it bothered me.\\&quot;, \\n    \\&quot;The app does some things right, but most of it is just annoying.\\&quot;        \\n]\\n\\ntrue_labels = [\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I can&#39;t believe how great this app is, it’s honestly a game-changer!\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;It’s not as bad as I expected, but still not great.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;The update did fix a lot of issues, so I’m glad they listened to feedback.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;It’s just another buggy version with more problems than before.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I&#39;m amazed by how quickly it works now, truly impressed.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;Oh look, the app works for once. Not sure if it&#39;s a fluke or progress.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;The new design is a pleasant surprise — I didn&#39;t expect it to be this good.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;The app keeps freezing when I need it most. Terrible experience.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;I didn’t think it was possible, but this update made things even worse.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;Wow, finally an update that makes sense. So happy about this!\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;At least the app doesn’t crash every five minutes now. That’s something.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I’ve never been so impressed by an app’s performance. Outstanding!\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;I’m sure it works for some people, but not for me. A lot of problems.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;It’s almost like the developers actually care now. Big improvement!\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;The app is still the same: slow, frustrating, and useless.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;The new features are cool, but the app is still very glitchy.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I wish I had known about this app sooner, it really does make a difference.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;I regret wasting my time on this app. I’ve had enough.\\&quot;\\n    \\&quot;POSITIVE\\&quot;,  # \\&quot;I’m so happy they fixed that bug, I didn’t realize how much it bothered me.\\&quot;\\n    \\&quot;NEGATIVE\\&quot;,  # \\&quot;The app does some things right, but most of it is just annoying.\\&quot;\\n]\\n\\nimport warnings\\nwarnings.filterwarnings(\\&quot;ignore\\&quot;)\\nfrom transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;^2Z&quot;,&quot;&quot;,&quot;^2[&quot;,null,&quot;^30&quot;,null,&quot;xp&quot;,100,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1918988,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2V&quot;,null,&quot;^V&quot;,null,&quot;^2W&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, ____)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, ____)\\n\\n# Generate predictions\\npreds_a = [____ for res in pipe_a(texts)]\\npreds_b = [____ for res in pipe_b(texts)]&quot;,&quot;^2X&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Load two pipelines (&lt;code&gt;pipe_a&lt;/code&gt; and &lt;code&gt;pipe_a&lt;/code&gt;) using the models &lt;code&gt;\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;&lt;/code&gt; and &lt;code&gt;\\&quot;abilfad/sentiment-binary-dicoding\\&quot;&lt;/code&gt;, respectively.&lt;/li&gt;\\n&lt;li&gt;Extract the &lt;code&gt;&#39;label&#39;&lt;/code&gt; values from the predictions of both pipelines.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^10&quot;,1,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n    check_function(\\&quot;transformers.pipeline\\&quot;, index=0, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_function(\\&quot;transformers.pipeline\\&quot;, index=1, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n\\n  has_code(\\&quot;preds_a\\\\s*=\\\\s*\\\\[\\\\s*res\\\\[\\\\s*(\\\\\\&quot;|\\\\&#39;)label(\\\\\\&quot;|\\\\&#39;)\\&quot;, not_typed_msg=\\&quot;Did you correctly extract the `&#39;label&#39;` using `res[&#39;label&#39;]` inside your first list comprehension?\\&quot;),\\n  has_code(\\&quot;preds_b\\\\s*=\\\\s*\\\\[\\\\s*res\\\\[\\\\s*(\\\\\\&quot;|\\\\&#39;)label(\\\\\\&quot;|\\\\&#39;)\\&quot;, not_typed_msg=\\&quot;Did you correctly extract the `&#39;label&#39;` using `res[&#39;label&#39;]` inside your second list comprehension?\\&quot;)\\n) &quot;,&quot;^2Y&quot;,&quot;&quot;,&quot;^2Z&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;abilfad/sentiment-binary-dicoding\\&quot;)\\n\\n# Generate predictions\\npreds_a = [res[\\&quot;label\\&quot;] for res in pipe_a(texts)]\\npreds_b = [res[\\&quot;label\\&quot;] for res in pipe_b(texts)]&quot;,&quot;^2[&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;In the list comprehension, each &lt;code&gt;res&lt;/code&gt; is a dictionary with a &lt;code&gt;&#39;label&#39;&lt;/code&gt; and a &lt;code&gt;&#39;score&#39;&lt;/code&gt;. Extract the &lt;code&gt;&#39;label&#39;&lt;/code&gt; to get the predictions.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^30&quot;,null,&quot;xp&quot;,50,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;^3&gt;&quot;,[[&quot;^ &quot;,&quot;^3?&quot;,0,&quot;^2W&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, ____)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, ____)\\n\\n# Generate predictions\\npreds_a = [____ for res in pipe_a(texts)]\\npreds_b = [____ for res in pipe_b(texts)]&quot;]]],[&quot;^ &quot;,&quot;id&quot;,1918989,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2V&quot;,null,&quot;^V&quot;,null,&quot;^2W&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;abilfad/sentiment-binary-dicoding\\&quot;)\\n\\n# Generate predictions\\npreds_a = [res[\\&quot;label\\&quot;] for res in pipe_a(texts)]\\npreds_b = [res[\\&quot;label\\&quot;] for res in pipe_b(texts)]\\n\\n# Evaluate accuracies\\nacc_a = ____\\nacc_b = ____\\nprint(f\\&quot;Accuracy - Model A: {acc_a:.2f}\\&quot;)\\nprint(f\\&quot;Accuracy - Model B: {acc_b:.2f}\\&quot;)&quot;,&quot;^2X&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Compute the accuracies of both models (&lt;code&gt;acc_a&lt;/code&gt; and &lt;code&gt;acc_b&lt;/code&gt;).&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^10&quot;,2,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n    check_function(\\&quot;transformers.pipeline\\&quot;, index=0, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_function(\\&quot;transformers.pipeline\\&quot;, index=1, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n\\n  has_code(\\&quot;preds_a\\\\s*=\\\\s*\\\\[\\\\s*res\\\\[\\\\s*(\\\\\\&quot;|\\\\&#39;)label(\\\\\\&quot;|\\\\&#39;)\\&quot;, not_typed_msg=\\&quot;Did you correctly extract the `&#39;label&#39;` using `res[&#39;label&#39;]` inside your first list comprehension?\\&quot;),\\n  has_code(\\&quot;preds_b\\\\s*=\\\\s*\\\\[\\\\s*res\\\\[\\\\s*(\\\\\\&quot;|\\\\&#39;)label(\\\\\\&quot;|\\\\&#39;)\\&quot;, not_typed_msg=\\&quot;Did you correctly extract the `&#39;label&#39;` using `res[&#39;label&#39;]` inside your second list comprehension?\\&quot;),\\n  check_or(\\n    has_code(\\&quot;acc_a\\\\s*=\\\\s*accuracy_score\\\\(\\\\s*true_labels\\\\s*,\\\\s*preds_a\\&quot;, not_typed_msg=\\&quot;Did you correctly calculate `acc_a` by calling `accuracy_score(true_labels, preds_a)`?\\&quot;),\\n    has_code(\\&quot;acc_a\\\\s*=\\\\s*accuracy_score\\\\(\\\\s*preds_a\\\\s*,\\\\s*true_labels\\&quot;, not_typed_msg=\\&quot;Did you correctly calculate `acc_a` by calling `accuracy_score(true_labels, preds_a)`?\\&quot;)\\n  ),\\n  check_or(\\n    has_code(\\&quot;acc_b\\\\s*=\\\\s*accuracy_score\\\\(\\\\s*true_labels\\\\s*,\\\\s*preds_b\\&quot;, not_typed_msg=\\&quot;Did you correctly calculate `acc_b` by calling `accuracy_score(true_labels, preds_b)`?\\&quot;),\\n    has_code(\\&quot;acc_b\\\\s*=\\\\s*accuracy_score\\\\(\\\\s*preds_b\\\\s*,\\\\s*true_labels\\&quot;, not_typed_msg=\\&quot;Did you correctly calculate `acc_b` by calling `accuracy_score(true_labels, preds_b)`?\\&quot;)\\n  )\\n)\\n\\nsuccess_msg(\\&quot;Excellent! You&#39;ve compared two models using real review data. This kind of evaluation helps identify the most reliable option, and in this case, Model B appears to perform better for our tasks, so it should be chosen for production.\\&quot;)&quot;,&quot;^2Y&quot;,&quot;&quot;,&quot;^2Z&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;abilfad/sentiment-binary-dicoding\\&quot;)\\n\\n# Generate predictions\\npreds_a = [res[\\&quot;label\\&quot;] for res in pipe_a(texts)]\\npreds_b = [res[\\&quot;label\\&quot;] for res in pipe_b(texts)]\\n\\n# Evaluate accuracies\\nacc_a = accuracy_score(true_labels, preds_a)\\nacc_b = accuracy_score(true_labels, preds_b)\\nprint(f\\&quot;Accuracy - Model A: {acc_a:.2f}\\&quot;)\\nprint(f\\&quot;Accuracy - Model B: {acc_b:.2f}\\&quot;)&quot;,&quot;^2[&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;The &lt;code&gt;accuracy_score&lt;/code&gt; function takes as inputs the &lt;code&gt;true_labels&lt;/code&gt; and the predictions.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^30&quot;,null,&quot;xp&quot;,50,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;^3&gt;&quot;,[[&quot;^ &quot;,&quot;^3?&quot;,0,&quot;^2W&quot;,&quot;from transformers import pipeline\\nfrom sklearn.metrics import accuracy_score\\n# Load sentiment analysis models\\npipe_a = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;distilbert-base-uncased-finetuned-sst-2-english\\&quot;)\\npipe_b = pipeline(task=\\&quot;sentiment-analysis\\&quot;, model=\\&quot;abilfad/sentiment-binary-dicoding\\&quot;)\\n\\n# Generate predictions\\npreds_a = [res[\\&quot;label\\&quot;] for res in pipe_a(texts)]\\npreds_b = [res[\\&quot;label\\&quot;] for res in pipe_b(texts)]\\n\\n# Evaluate accuracies\\nacc_a = ____\\nacc_b = ____\\nprint(f\\&quot;Accuracy - Model A: {acc_a:.2f}\\&quot;)\\nprint(f\\&quot;Accuracy - Model B: {acc_b:.2f}\\&quot;)&quot;]]]],&quot;^38&quot;,&quot;python&quot;,&quot;^3&lt;&quot;,0.12333672235765003,&quot;^3=&quot;,1918987],[&quot;^ &quot;,&quot;id&quot;,1918990,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^2V&quot;,null,&quot;^V&quot;,&quot;Zero-shot classification and QNLI&quot;,&quot;^2W&quot;,&quot;&quot;,&quot;^2X&quot;,null,&quot;^10&quot;,5,&quot;sct&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;&quot;,&quot;^2Z&quot;,&quot;&quot;,&quot;^2[&quot;,null,&quot;^30&quot;,null,&quot;xp&quot;,50,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,&quot;learn-heavy&quot;,&quot;^34&quot;,null,&quot;^35&quot;,null,&quot;^36&quot;,56.25,&quot;^37&quot;,&quot;course_41242_c7803789f75d0048781b9d6b6c08a49e&quot;,&quot;key&quot;,&quot;395f17cdea&quot;,&quot;^38&quot;,&quot;python&quot;,&quot;^39&quot;,41242,&quot;^3:&quot;,133925,&quot;^3;&quot;,&quot;v0&quot;,&quot;^3&lt;&quot;,0.9651857447035519,&quot;^3=&quot;,1918990],[&quot;^ &quot;,&quot;id&quot;,1918991,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2V&quot;,&quot;&lt;p&gt;A company receives hundreds of support tickets daily, covering topics like billing issues, technical problems, and account management. Manually sorting these tickets is inefficient. You&#39;ve been asked to use a zero-shot classification model to automatically categorize incoming ticket messages without needing a custom-trained classifier.&lt;/p&gt;&quot;,&quot;^V&quot;,&quot;Zero-shot classification of support tickets&quot;,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the zero-shot classifier\\nclassifier = ____\\n\\nticket_text = \\&quot;I was charged twice for my subscription this month. Can you please refund the extra charge?\\&quot;\\ncandidate_labels = [\\&quot;Billing\\&quot;, \\&quot;Technical Issue\\&quot;, \\&quot;Account Access\\&quot;]\\n\\n# Classify the ticket\\nresult = ____\\n\\nprint(result[&#39;labels&#39;])\\nprint(result[&#39;scores&#39;])&quot;,&quot;^2X&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Create a zero-shot &lt;code&gt;classifier&lt;/code&gt; pipeline using the &lt;code&gt;\\&quot;MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\\&quot;&lt;/code&gt; model.&lt;/li&gt;\\n&lt;li&gt;Use it to classify the &lt;code&gt;ticket_text&lt;/code&gt; into one of the categories listed in &lt;code&gt;candidate_labels&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^10&quot;,6,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;ticket_text\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `ticket_text` variable.\\&quot;),\\n  check_object(\\&quot;candidate_labels\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `candidate_labels` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;)\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\n) \\n\\n\\nsuccess_msg(\\&quot;Great job! Based on the prediction probabilities, the model is most confident that this ticket belongs in the Billing category. This enables the company to automatically route tickets to the right team, reducing response time and improving customer satisfaction without needing to retrain models for each category.\\&quot;)&quot;,&quot;^2Y&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;^2Z&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the zero-shot classifier\\nclassifier = pipeline(task=\\&quot;zero-shot-classification\\&quot;, model=\\&quot;MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\\&quot;)\\n\\nticket_text = \\&quot;I was charged twice for my subscription this month. Can you please refund the extra charge?\\&quot;\\ncandidate_labels = [\\&quot;Billing\\&quot;, \\&quot;Technical Issue\\&quot;, \\&quot;Account Access\\&quot;]\\n\\n# Classify the ticket\\nresult = classifier(ticket_text, candidate_labels)\\n\\nprint(result[&#39;labels&#39;])\\nprint(result[&#39;scores&#39;])&quot;,&quot;^2[&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use &lt;code&gt;zero-shot-classification&lt;/code&gt; as a task when defining the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;li&gt;Pass the &lt;code&gt;ticket_text&lt;/code&gt; and &lt;code&gt;candidate_labels&lt;/code&gt; as arguments to the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^30&quot;,null,&quot;xp&quot;,100,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;^3&gt;&quot;,[[&quot;^ &quot;,&quot;^3?&quot;,0,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the zero-shot classifier\\nclassifier = ____\\n\\nticket_text = \\&quot;I was charged twice for my subscription this month. Can you please refund the extra charge?\\&quot;\\ncandidate_labels = [\\&quot;Billing\\&quot;, \\&quot;Technical Issue\\&quot;, \\&quot;Account Access\\&quot;]\\n\\n# Classify the ticket\\nresult = ____\\n\\nprint(result[&#39;labels&#39;])\\nprint(result[&#39;scores&#39;])&quot;]],&quot;^38&quot;,&quot;python&quot;,&quot;^3&lt;&quot;,0.7513952445580347,&quot;^3=&quot;,1918991],[&quot;^ &quot;,&quot;id&quot;,1918992,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2V&quot;,&quot;&lt;p&gt;A content moderation team in a large tech company needs to automatically validate whether a passage from a knowledge base answers a customer query. They want to speed up the process using a pre-trained QNLI model to assess the relevance of each response. Your goal is to implement a solution that can classify whether a given passage contains the answer to a specific question.&lt;/p&gt;&quot;,&quot;^V&quot;,&quot;Does the text answer the question?&quot;,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the QNLI pipeline\\nclassifier = ____\\n\\npassage = \\&quot;Our refund policy allows customers to return any item within 30 days of purchase, provided the item is in its original condition and accompanied by the receipt. Refunds are issued to the original payment method within 5–7 business days.\\&quot;\\nquestion = \\&quot;Can I get a refund if I return a product after 20 days?\\&quot;\\n\\n# Get the result\\nresult = ____\\nprint(result)&quot;,&quot;^2X&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a &lt;code&gt;classifier&lt;/code&gt; pipeline with a suitable QNLI model, such as &lt;code&gt;\\&quot;cross-encoder/qnli-electra-base\\&quot;&lt;/code&gt;.&lt;/li&gt;\\n&lt;li&gt;Use this pipeline to evaluate whether the given &lt;code&gt;passage&lt;/code&gt; answers the &lt;code&gt;question&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^10&quot;,7,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;passage\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `ticket_text` variable.\\&quot;),\\n  check_object(\\&quot;question\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `candidate_labels` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\n  has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question` as the value for the `&#39;text&#39;` key in the classifier?\\&quot;),\\n  has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text_pair(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*passage\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `passage` as the value for the `&#39;text_pair&#39;` key in the classifier?\\&quot;)\\n)\\n\\n\\nsuccess_msg(\\&quot;Well done! Based on the QNLI model, the passage answers the question with a confidence of 97%. This solution helps the content moderation team automate knowledge validation and improves response accuracy on customer support platforms, ensuring users get timely and relevant answers.\\&quot;)&quot;,&quot;^2Y&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;^2Z&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the QNLI pipeline\\nclassifier = pipeline(task=\\&quot;text-classification\\&quot;, model=\\&quot;cross-encoder/qnli-electra-base\\&quot;)\\n\\npassage = \\&quot;Our refund policy allows customers to return any item within 30 days of purchase, provided the item is in its original condition and accompanied by the receipt. Refunds are issued to the original payment method within 5–7 business days.\\&quot;\\nquestion = \\&quot;Can I get a refund if I return a product after 20 days?\\&quot;\\n\\n# Get the result\\nresult = classifier({\\n    \\&quot;text\\&quot;: question,\\n    \\&quot;text_pair\\&quot;: passage\\n})\\nprint(result)&quot;,&quot;^2[&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;QNLI is a &lt;code&gt;\\&quot;text-classification\\&quot;&lt;/code&gt; task.&lt;/li&gt;\\n&lt;li&gt;Ensure the &lt;code&gt;passage&lt;/code&gt; and &lt;code&gt;question&lt;/code&gt; are passed in a dictionary, with &lt;code&gt;\\&quot;text\\&quot;&lt;/code&gt; as the &lt;code&gt;question&lt;/code&gt; and &lt;code&gt;\\&quot;text_pair\\&quot;&lt;/code&gt; as the &lt;code&gt;passage&lt;/code&gt;.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^30&quot;,null,&quot;xp&quot;,100,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;^3&gt;&quot;,[[&quot;^ &quot;,&quot;^3?&quot;,0,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the QNLI pipeline\\nclassifier = ____\\n\\npassage = \\&quot;Our refund policy allows customers to return any item within 30 days of purchase, provided the item is in its original condition and accompanied by the receipt. Refunds are issued to the original payment method within 5–7 business days.\\&quot;\\nquestion = \\&quot;Can I get a refund if I return a product after 20 days?\\&quot;\\n\\n# Get the result\\nresult = ____\\nprint(result)&quot;]],&quot;^38&quot;,&quot;python&quot;,&quot;^3&lt;&quot;,0.0926165734285449,&quot;^3=&quot;,1918992],[&quot;^ &quot;,&quot;id&quot;,1918993,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^2V&quot;,null,&quot;^V&quot;,&quot;Question similarity and grammatical correctness&quot;,&quot;^2W&quot;,&quot;&quot;,&quot;^2X&quot;,null,&quot;^10&quot;,8,&quot;sct&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;&quot;,&quot;^2Z&quot;,&quot;&quot;,&quot;^2[&quot;,null,&quot;^30&quot;,null,&quot;xp&quot;,50,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,&quot;learn-heavy&quot;,&quot;^34&quot;,null,&quot;^35&quot;,null,&quot;^36&quot;,56.25,&quot;^37&quot;,&quot;course_41242_4a3531e4ba5bcfe11ee135ca20231603&quot;,&quot;key&quot;,&quot;d87cc29db8&quot;,&quot;^38&quot;,&quot;python&quot;,&quot;^39&quot;,41242,&quot;^3:&quot;,133925,&quot;^3;&quot;,&quot;v0&quot;,&quot;^3&lt;&quot;,0.2609561184083786,&quot;^3=&quot;,1918993],[&quot;^ &quot;,&quot;id&quot;,1918994,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2V&quot;,&quot;&lt;p&gt;A startup is developing a Q&amp;amp;A assistant to improve the user experience on their support forum. One key feature is to detect when users ask the same question using different words. You&#39;ve been asked to implement a solution using a pre-trained QQP model that can determine whether two questions are duplicates.&lt;/p&gt;&quot;,&quot;^V&quot;,&quot;Detecting duplicate questions&quot;,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = ____(task=\\&quot;____\\&quot;, model=\\&quot;____\\&quot;)\\n\\nquestion_1 = \\&quot;What&#39;s the process to change my password?\\&quot;\\nquestion_2 = \\&quot;How do I reset my account password?\\&quot;\\n\\n# Detect if the two questions are paraphrases\\nresult = classifier({\\n    \\&quot;____\\&quot;: ____,\\n    \\&quot;____\\&quot;: ____\\n})\\n\\nprint(result)&quot;,&quot;^2X&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a suitable &lt;code&gt;classifier&lt;/code&gt; pipeline with the &lt;code&gt;\\&quot;textattack/bert-base-uncased-QQP\\&quot;&lt;/code&gt; model.&lt;/li&gt;\\n&lt;li&gt;Use the pipeline to classify whether &lt;code&gt;question_1&lt;/code&gt; and &lt;code&gt;question_2&lt;/code&gt; are paraphrases.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^10&quot;,9,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;question_1\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `question_1` variable.\\&quot;),\\n  check_object(\\&quot;question_2\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `question_2` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\n  check_or(\\n    has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question_1\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question_1` as the value for the `&#39;text&#39;` key in the classifier?\\&quot;),\\n    has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question_2\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question_1` as the value for the `&#39;text&#39;` key in the classifier?\\&quot;),\\n  ),\\n  check_or(\\n    has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text_pair(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question_1\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question_2` as the value for the `&#39;text_pair&#39;` key in the classifier?\\&quot;),\\n    has_code(\\&quot;(\\\\\\&quot;|\\\\&#39;)text_pair(\\\\\\&quot;|\\\\&#39;)\\\\s*:\\\\s*question_2\\&quot;, \\n         not_typed_msg=\\&quot;Did you correctly pass `question_2` as the value for the `&#39;text_pair&#39;` key in the classifier?\\&quot;),\\n  ),\\n  check_function(&#39;print&#39;).check_args(0).has_equal_value(incorrect_msg=\\&quot;Did you print the `result` variable?\\&quot;)\\n)\\n\\nsuccess_msg(\\&quot;Great work! The QQP model detected that these questions are 57% similar! This helps reduce duplicate content on the support forum, streamlining search results and ensuring users quickly find accurate answers, boosting efficiency for both users and support staff.\\&quot;)&quot;,&quot;^2Y&quot;,&quot;from transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;^2Z&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = pipeline(task=\\&quot;text-classification\\&quot;, model=\\&quot;textattack/distilbert-base-uncased-QQP\\&quot;)\\n\\nquestion_1 = \\&quot;What&#39;s the process to change my password?\\&quot;\\nquestion_2 = \\&quot;How do I reset my account password?\\&quot;\\n\\n# Detect if the two questions are paraphrases\\nresult = classifier({\\n    \\&quot;text\\&quot;: question_1,\\n    \\&quot;text_pair\\&quot;: question_2\\n})\\n\\nprint(result)&quot;,&quot;^2[&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;To detect if two questions are paraphrases, we need a &lt;code&gt;text-classification&lt;/code&gt; task when defining the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;li&gt;Pass the questions as a dictionary with &lt;code&gt;\\&quot;text\\&quot;&lt;/code&gt; and &lt;code&gt;\\&quot;text_pair\\&quot;&lt;/code&gt; keys to the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^30&quot;,null,&quot;xp&quot;,100,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;^3&gt;&quot;,[[&quot;^ &quot;,&quot;^3?&quot;,0,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = ____(task=\\&quot;____\\&quot;, model=\\&quot;____\\&quot;)\\n\\nquestion_1 = \\&quot;What&#39;s the process to change my password?\\&quot;\\nquestion_2 = \\&quot;How do I reset my account password?\\&quot;\\n\\n# Detect if the two questions are paraphrases\\nresult = classifier({\\n    \\&quot;____\\&quot;: ____,\\n    \\&quot;____\\&quot;: ____\\n})\\n\\nprint(result)&quot;]],&quot;^38&quot;,&quot;python&quot;,&quot;^3&lt;&quot;,0.27559627032120115,&quot;^3=&quot;,1918994],[&quot;^ &quot;,&quot;id&quot;,1918995,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2V&quot;,&quot;&lt;p&gt;An educational app is being built to help users improve their grammar. One core feature automatically checks whether user-submitted sentences are grammatically acceptable. You&#39;ve been asked to implement this feature using a model trained on the Corpus of Linguistic Acceptability (CoLA) to classify sentence correctness.&lt;/p&gt;&quot;,&quot;^V&quot;,&quot;Checking grammatical correctness&quot;,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = ____\\n\\nuser_text = \\&quot;Although she was knowing the answer, she didn&#39;t raised her hand during the class discussion.\\&quot;\\n\\n# Classify grammatical acceptability\\nresult = ____\\n\\nprint(result)&quot;,&quot;^2X&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Initialize a &lt;code&gt;classifier&lt;/code&gt; pipeline with the &lt;code&gt;\\&quot;textattack/bert-base-uncased-CoLA\\&quot;&lt;/code&gt; model.&lt;/li&gt;\\n&lt;li&gt;Use the pipeline to check if the &lt;code&gt;user_text&lt;/code&gt; is grammatically acceptable.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^10&quot;,10,&quot;sct&quot;,&quot;sig = sig_from_params(param(\\&quot;task\\&quot;, param.POSITIONAL_OR_KEYWORD),\\n                      param(\\&quot;model\\&quot;, param.POSITIONAL_OR_KEYWORD))\\n\\nEx().multi(\\n  check_object(\\&quot;classifier\\&quot;),\\n    check_function(\\&quot;transformers.pipeline\\&quot;, signature=sig).multi(\\n    check_args(\\&quot;model\\&quot;).has_equal_ast(),\\n    check_args(\\&quot;task\\&quot;).has_equal_ast()),\\n  check_object(\\&quot;user_text\\&quot;).has_equal_value(\\&quot;Make sure you don&#39;t modify the `user_text` variable.\\&quot;),\\n  check_function(\\&quot;classifier\\&quot;),\\n  check_function(&#39;print&#39;).check_args(0).has_equal_value(incorrect_msg=\\&quot;Did you print the `result` variable?\\&quot;)\\n)\\n\\nsuccess_msg(\\&quot;Well done! The model found the sentence to be 78% acceptable. This feature will power instant grammar feedback in the educational app, helping users improve their writing skills and build stronger language habits over time.\\&quot;)&quot;,&quot;^2Y&quot;,&quot;import warnings\\nwarnings.filterwarnings(\\&quot;ignore\\&quot;)\\nfrom transformers import logging\\nlogging.set_verbosity_error()&quot;,&quot;^2Z&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = pipeline(task=\\&quot;text-classification\\&quot;, model=\\&quot;textattack/bert-base-uncased-CoLA\\&quot;)\\n\\nuser_text = \\&quot;Although she was knowing the answer, she didn&#39;t raised her hand during the class discussion.\\&quot;\\n\\n# Classify grammatical acceptability\\nresult = classifier(user_text)\\n\\nprint(result)&quot;,&quot;^2[&quot;,&quot;&lt;ul&gt;\\n&lt;li&gt;Use the &lt;code&gt;\\&quot;text-classification\\&quot;&lt;/code&gt; task when creating the &lt;code&gt;classifier&lt;/code&gt; pipeline.&lt;/li&gt;\\n&lt;li&gt;Pass the sentence directly to the pipeline to classify its grammaticality.&lt;/li&gt;\\n&lt;/ul&gt;&quot;,&quot;^30&quot;,null,&quot;xp&quot;,100,&quot;^31&quot;,[],&quot;^32&quot;,[],&quot;^33&quot;,&quot;&quot;,&quot;^1?&quot;,null,&quot;^1@&quot;,null,&quot;^1A&quot;,null,&quot;^3&gt;&quot;,[[&quot;^ &quot;,&quot;^3?&quot;,0,&quot;^2W&quot;,&quot;from transformers import pipeline\\n\\n# Initialize the pipeline\\nclassifier = ____\\n\\nuser_text = \\&quot;Although she was knowing the answer, she didn&#39;t raised her hand during the class discussion.\\&quot;\\n\\n# Classify grammatical acceptability\\nresult = ____\\n\\nprint(result)&quot;]],&quot;^38&quot;,&quot;python&quot;,&quot;^3&lt;&quot;,0.10163630465043383,&quot;^3=&quot;,1918995]]]]],&quot;^H&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;NOT_FETCHED&quot;,&quot;^13&quot;,null]]],&quot;^Y&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^13&quot;,[[&quot;^ &quot;,&quot;^Z&quot;,133923,&quot;^[&quot;,1,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888943,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1903567,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1903568,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1903570,&quot;^10&quot;,2,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1903571,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1903572,&quot;^10&quot;,2]]],[&quot;^ &quot;,&quot;id&quot;,1903569,&quot;^10&quot;,3]],&quot;id&quot;,111824,&quot;^10&quot;,1,&quot;^V&quot;,&quot;Introduction to natural language processing&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133923,&quot;^[&quot;,1,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1908634,&quot;^10&quot;,4],[&quot;^ &quot;,&quot;id&quot;,1908635,&quot;^10&quot;,5],[&quot;^ &quot;,&quot;id&quot;,1908636,&quot;^10&quot;,6]],&quot;id&quot;,116314,&quot;^10&quot;,2,&quot;^V&quot;,&quot;Stop words and punctuation handling&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133923,&quot;^[&quot;,1,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1908637,&quot;^10&quot;,7],[&quot;^ &quot;,&quot;id&quot;,1908638,&quot;^10&quot;,8,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1908639,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1908640,&quot;^10&quot;,2]]],[&quot;^ &quot;,&quot;id&quot;,1914343,&quot;^10&quot;,8],[&quot;^ &quot;,&quot;id&quot;,1914344,&quot;^10&quot;,9],[&quot;^ &quot;,&quot;id&quot;,1908641,&quot;^10&quot;,10]],&quot;id&quot;,116315,&quot;^10&quot;,3,&quot;^V&quot;,&quot;Text normalization techniques&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133924,&quot;^[&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911685,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1888944,&quot;^10&quot;,1,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888945,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1888946,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1888947,&quot;^10&quot;,3]]],[&quot;^ &quot;,&quot;id&quot;,1911686,&quot;^10&quot;,2,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911687,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911688,&quot;^10&quot;,2]]],[&quot;^ &quot;,&quot;id&quot;,1914345,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1914346,&quot;^10&quot;,3],[&quot;^ &quot;,&quot;id&quot;,1911689,&quot;^10&quot;,4,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911690,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911691,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911692,&quot;^10&quot;,2]]],[&quot;^ &quot;,&quot;id&quot;,1945422,&quot;^10&quot;,5]],&quot;id&quot;,111825,&quot;^10&quot;,1,&quot;^V&quot;,&quot;Bag-of-Words representation&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133924,&quot;^[&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911693,&quot;^10&quot;,6],[&quot;^ &quot;,&quot;id&quot;,1911694,&quot;^10&quot;,7],[&quot;^ &quot;,&quot;id&quot;,1911695,&quot;^10&quot;,8,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911696,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911697,&quot;^10&quot;,2]]]],&quot;id&quot;,115123,&quot;^10&quot;,2,&quot;^V&quot;,&quot;TF-IDF vectorization&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133924,&quot;^[&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1903573,&quot;^10&quot;,9],[&quot;^ &quot;,&quot;id&quot;,1911698,&quot;^10&quot;,10],[&quot;^ &quot;,&quot;id&quot;,1911699,&quot;^10&quot;,11,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1911700,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1911701,&quot;^10&quot;,2]]]],&quot;id&quot;,117071,&quot;^10&quot;,3,&quot;^V&quot;,&quot;Embeddings&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133925,&quot;^[&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888948,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1918984,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1918985,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1918986,&quot;^10&quot;,3],[&quot;^ &quot;,&quot;id&quot;,1918987,&quot;^10&quot;,4,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1918988,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1918989,&quot;^10&quot;,2]]]],&quot;id&quot;,111826,&quot;^10&quot;,1,&quot;^V&quot;,&quot;Hugging Face pipelines for sentiment analysis&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133925,&quot;^[&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1918990,&quot;^10&quot;,5],[&quot;^ &quot;,&quot;id&quot;,1918991,&quot;^10&quot;,6],[&quot;^ &quot;,&quot;id&quot;,1918992,&quot;^10&quot;,7]],&quot;id&quot;,118738,&quot;^10&quot;,2,&quot;^V&quot;,&quot;Zero-shot classification and QNLI&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133925,&quot;^[&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1918993,&quot;^10&quot;,8],[&quot;^ &quot;,&quot;id&quot;,1918994,&quot;^10&quot;,9],[&quot;^ &quot;,&quot;id&quot;,1918995,&quot;^10&quot;,10]],&quot;id&quot;,118739,&quot;^10&quot;,3,&quot;^V&quot;,&quot;Question similarity and grammatical correctness&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133926,&quot;^[&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888949,&quot;^10&quot;,1,&quot;^11&quot;,[[&quot;^ &quot;,&quot;id&quot;,1888950,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1888951,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1888952,&quot;^10&quot;,3],[&quot;^ &quot;,&quot;id&quot;,1888953,&quot;^10&quot;,4]]],[&quot;^ &quot;,&quot;id&quot;,1927536,&quot;^10&quot;,1],[&quot;^ &quot;,&quot;id&quot;,1927537,&quot;^10&quot;,2],[&quot;^ &quot;,&quot;id&quot;,1927538,&quot;^10&quot;,3]],&quot;id&quot;,111827,&quot;^10&quot;,1,&quot;^V&quot;,&quot;Token classification&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133926,&quot;^[&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1927539,&quot;^10&quot;,4],[&quot;^ &quot;,&quot;id&quot;,1927540,&quot;^10&quot;,5],[&quot;^ &quot;,&quot;id&quot;,1927541,&quot;^10&quot;,6]],&quot;id&quot;,120731,&quot;^10&quot;,2,&quot;^V&quot;,&quot;Question answering&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133926,&quot;^[&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1927542,&quot;^10&quot;,7],[&quot;^ &quot;,&quot;id&quot;,1927543,&quot;^10&quot;,8],[&quot;^ &quot;,&quot;id&quot;,1927544,&quot;^10&quot;,9],[&quot;^ &quot;,&quot;id&quot;,1927545,&quot;^10&quot;,10]],&quot;id&quot;,120732,&quot;^10&quot;,3,&quot;^V&quot;,&quot;Sequence generation tasks&quot;],[&quot;^ &quot;,&quot;^Z&quot;,133926,&quot;^[&quot;,4,&quot;^F&quot;,[[&quot;^ &quot;,&quot;id&quot;,1927546,&quot;^10&quot;,11]],&quot;id&quot;,120733,&quot;^10&quot;,4,&quot;^V&quot;,&quot;Congratulations&quot;]]]]],&quot;sharedImage&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;NOT_FETCHED&quot;,&quot;^13&quot;,null]]],&quot;^S&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^13&quot;,[&quot;^ &quot;,&quot;^T&quot;,&quot;course&quot;,&quot;^U&quot;,41242,&quot;^V&quot;,&quot;Course Notes: Natural Language Processing (NLP) in Python&quot;]]]],&quot;courseImages&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^13&quot;,[&quot;^ &quot;,&quot;imageTag&quot;,&quot;course-41242-master:cba75f8fc9b9&quot;,&quot;^B&quot;,&quot;singleImage&quot;]]]],&quot;categoryPages&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^13&quot;,[[&quot;^ &quot;,&quot;^16&quot;,&quot;power-bi&quot;,&quot;facet&quot;,[&quot;^ &quot;,&quot;technology_array&quot;,[&quot;Power BI&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;r&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3E&quot;,[&quot;R&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;sql&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3E&quot;,[&quot;SQL&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;tableau&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3E&quot;,[&quot;Tableau&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;azure&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3E&quot;,[&quot;Azure&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;probability-and-statistics&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;topic_array&quot;,[&quot;Probability &amp; Statistics&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;artificial-intelligence&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3F&quot;,[&quot;Artificial Intelligence&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;machine-learning&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3F&quot;,[&quot;Machine Learning&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;data-engineering&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3F&quot;,[&quot;Data Engineering&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;data-visualization&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3F&quot;,[&quot;Data Visualization&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;data-analysis&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3F&quot;,[&quot;Reporting&quot;,&quot;Data Manipulation&quot;,&quot;Data Preparation&quot;,&quot;Exploratory Data Analysis&quot;,&quot;Data Visualization&quot;]]],[&quot;^ &quot;,&quot;^16&quot;,&quot;python&quot;,&quot;^3D&quot;,[&quot;^ &quot;,&quot;^3E&quot;,[&quot;Python&quot;]]]]]]],&quot;translatedCourses&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^13&quot;,[&quot;^ &quot;,&quot;58&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;672&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;735&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;799&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;1477&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;1531&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;1532&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;1606&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;1607&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;1796&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;1975&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;2072&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;2906&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;3423&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;3629&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;4205&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;4267&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;4452&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;4914&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;5065&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;6079&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6199&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6280&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;6554&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;6576&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6612&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;6919&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;7319&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;7355&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;7823&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;13023&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;13185&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;13203&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13274&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;13367&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;13369&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;13371&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;13690&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;13698&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;13706&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;14519&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;14739&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;14989&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;15108&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;15192&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;15424&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;15876&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;16459&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16470&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16473&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;16921&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16937&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;17118&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;17591&quot;,[&quot;fr&quot;],&quot;17602&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;17605&quot;,[&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;19197&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;19854&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;19930&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;20692&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;20822&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;20891&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;21394&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;21544&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;21701&quot;,[&quot;es&quot;],&quot;21983&quot;,[&quot;es&quot;],&quot;22066&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;],&quot;22639&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;22723&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;22812&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;23080&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;23983&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;23991&quot;,[&quot;pt&quot;,&quot;fr&quot;,&quot;es&quot;,&quot;de&quot;],&quot;24098&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24252&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;24364&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;24372&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;24388&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;24558&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;24852&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;24865&quot;,[&quot;pt&quot;],&quot;24878&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;24896&quot;,[&quot;de&quot;,&quot;pt&quot;,&quot;es&quot;,&quot;fr&quot;],&quot;24907&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;],&quot;25412&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;25472&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;25473&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25475&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;25711&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;25814&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;],&quot;25923&quot;,[&quot;de&quot;],&quot;25942&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;26827&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;27336&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;27391&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;28169&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;28173&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;28303&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;28314&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;28318&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;28765&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;28767&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;28826&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;28921&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;28944&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;28946&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29081&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29092&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;29094&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29140&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29143&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;29157&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29302&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;29303&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;29304&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;tr&quot;,&quot;it&quot;],&quot;29355&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;29453&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;29478&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;29490&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29533&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29573&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;29712&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29744&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;,&quot;id&quot;,&quot;nl&quot;],&quot;29830&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29835&quot;,[&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;29902&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;,&quot;id&quot;,&quot;nl&quot;],&quot;29911&quot;,[&quot;de&quot;],&quot;29943&quot;,[&quot;pt&quot;,&quot;de&quot;,&quot;es&quot;],&quot;29968&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;30519&quot;,[&quot;it&quot;,&quot;tr&quot;,&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;30523&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;30563&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;30656&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;30891&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;30893&quot;,[&quot;de&quot;,&quot;fr&quot;,&quot;es&quot;,&quot;pt&quot;],&quot;31224&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;31361&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;31794&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;31939&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;tr&quot;,&quot;fr&quot;,&quot;it&quot;],&quot;31950&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;32058&quot;,[&quot;es&quot;],&quot;32086&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;32245&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;32271&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;32326&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;32428&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;32439&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;tr&quot;,&quot;it&quot;],&quot;32476&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;32509&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;32613&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;id&quot;,&quot;nl&quot;],&quot;32623&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;32669&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;32718&quot;,[&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;es&quot;],&quot;32740&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;it&quot;,&quot;tr&quot;],&quot;32932&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;tr&quot;,&quot;it&quot;,&quot;id&quot;,&quot;nl&quot;],&quot;33286&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;33321&quot;,[&quot;fr&quot;,&quot;de&quot;,&quot;es&quot;,&quot;pt&quot;],&quot;33409&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;33412&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;tr&quot;,&quot;it&quot;],&quot;33509&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;33554&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;33674&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;33727&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;33848&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;33893&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;33937&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;,&quot;tr&quot;,&quot;it&quot;],&quot;34425&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;34598&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34614&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;tr&quot;,&quot;it&quot;],&quot;34616&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;34777&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;fr&quot;],&quot;34857&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;34919&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;34961&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;35064&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;35160&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;35209&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;35244&quot;,[&quot;it&quot;,&quot;tr&quot;,&quot;fr&quot;,&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;35336&quot;,[&quot;fr&quot;,&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;35360&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;35486&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35555&quot;,[&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;es&quot;],&quot;35597&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;35645&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;35684&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;35704&quot;,[&quot;de&quot;,&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;35908&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;35927&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35929&quot;,[&quot;it&quot;,&quot;tr&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;es&quot;,&quot;de&quot;],&quot;35934&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;36079&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;36157&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;36160&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;36164&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;36398&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;36399&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;36480&quot;,[&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;es&quot;],&quot;36814&quot;,[&quot;de&quot;],&quot;37483&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;37627&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;37838&quot;,[&quot;de&quot;,&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;37994&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;37998&quot;,[&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;es&quot;],&quot;38116&quot;,[&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;38170&quot;,[&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;38549&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;38716&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;id&quot;,&quot;nl&quot;,&quot;de&quot;],&quot;38786&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;39146&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;39207&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;39310&quot;,[&quot;es&quot;,&quot;fr&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;39583&quot;,[&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;39676&quot;,[&quot;pt&quot;],&quot;39703&quot;,[&quot;de&quot;,&quot;fr&quot;,&quot;es&quot;,&quot;pt&quot;],&quot;39711&quot;,[&quot;fr&quot;],&quot;40124&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;de&quot;],&quot;41087&quot;,[&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;tr&quot;,&quot;it&quot;],&quot;41242&quot;,[&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;,&quot;es&quot;],&quot;41513&quot;,[&quot;es&quot;],&quot;42942&quot;,[&quot;es&quot;,&quot;fr&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;id&quot;,&quot;nl&quot;],&quot;43039&quot;,[&quot;de&quot;,&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;43565&quot;,[&quot;de&quot;,&quot;es&quot;,&quot;pt&quot;,&quot;fr&quot;,&quot;id&quot;,&quot;nl&quot;]]]]]]]],&quot;settings&quot;,[&quot;^?&quot;,[&quot;uiTheme&quot;,&quot;DARK&quot;,&quot;feedbackRatingStatus&quot;,&quot;NONE&quot;,&quot;mobileView&quot;,&quot;CONTEXT&quot;]],&quot;streakInfo&quot;,[&quot;^ &quot;,&quot;^B&quot;,&quot;StreakUnknown&quot;],&quot;systemStatus&quot;,[&quot;^?&quot;,[&quot;indicator&quot;,&quot;none&quot;,&quot;description&quot;,&quot;No status has been fetched from the Status Page.&quot;]],&quot;user&quot;,[&quot;^?&quot;,[&quot;status&quot;,&quot;not_initiate&quot;,&quot;settings&quot;,[&quot;^?&quot;,[&quot;aiFlags&quot;,[&quot;^?&quot;,[&quot;aiSolutionExplanationEnabled&quot;,false,&quot;aiErrorExplanationEnabled&quot;,false]]]]]],&quot;userDifficulty&quot;,[&quot;^ &quot;,&quot;^3?&quot;,0,&quot;exercise_record&quot;,[]],&quot;images&quot;,[&quot;^ &quot;,&quot;^3B&quot;,&quot;course-41242-master:cba75f8fc9b9&quot;,&quot;^B&quot;,&quot;singleImage&quot;]]]]";</script><script>window.PRELOADED_LANGUAGE = "en";</script><div id="root"><div class="theme progress-indicator--visible"><style data-emotion="css 19enzrs">.css-19enzrs{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#F7F7FC;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:50px;padding-left:10px;padding-right:10px;position:relative;z-index:15;}</style><header data-cy="alpa-navbar" class="css-19enzrs"><style data-emotion="css vpr568">.css-vpr568{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;}</style><div class="css-vpr568"><style data-emotion="css 19lbh5u">.css-19lbh5u{padding-left:6px;padding-right:6px;}</style><style data-emotion="css 95343f">.css-95343f{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;z-index:0;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;padding-left:6px;padding-right:6px;}.css-95343f::before{border-radius:2px;content:"";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-95343f:active{background-color:transparent;}.css-95343f:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-95343f:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-95343f:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-95343f >*{z-index:1;}</style><a data-waffles-component="button" class="alpa-navbar-logo css-95343f" data-cy="header-logo" data-testid="alpa-navbar-logo" data-trackid="alpa-navbar-logo" href="https://www.datacamp.com" aria-label="landing"><style data-emotion="css 61bni1">.css-61bni1{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:100%;gap:8px;}</style><span class="css-61bni1"><svg data-waffles-component="brand" viewbox="0 0 27 35" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" height="28" class="css-0"><path clip-rule="evenodd" d="M11.699 8.514v8.333L2.858 21.89V3.44l8.841 5.074zm2.861 17.507v-7.51l11.84-6.757-2.88-1.65-8.96 5.112V7.68a1.442 1.442 0 0 0-.718-1.242L3.056.256C3.027.238 2.998.224 2.97.21A2.064 2.064 0 0 0 0 2.07v21.184a2.067 2.067 0 0 0 2.971 1.865l.082-.042 8.64-4.933v6.72c.002.513.277.987.722 1.243L23.502 34.4l2.88-1.651-11.822-6.728z" fill="var(--wf-brand--text, #05192D)" fill-rule="evenodd"/></svg></span></a><nav aria-label="Breadcrumb" data-testid="alpa-navbar-breadcrumbs"><style data-emotion="css 1goqhco">.css-1goqhco{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding:0;}.css-1goqhco div[aria-hidden='true']{color:#5D6A77;display:none;padding:0 4px;}.css-1goqhco div[aria-hidden='true']:first-of-type{display:inline-block;}@media screen and (min-width: 820px){.css-1goqhco div[aria-hidden='true']{display:inline-block;}}.css-1goqhco li{display:none;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;list-style:none;}@media screen and (min-width: 820px){.css-1goqhco li{display:inline-block;}}.css-1goqhco li:first-of-type{display:inline-block;}.css-1goqhco li:last-of-type{display:inline-block;}.css-1goqhco li a{color:#05192D;font-weight:normal;height:30px;line-height:21px;min-height:unset;padding:2px;}.css-1goqhco li a span{display:inline-block;max-width:20vw;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}.css-1goqhco li:last-of-type a{font-weight:bold;}</style><ol itemscope itemtype="http://schema.org/BreadcrumbList" class="css-1goqhco"><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><style data-emotion="css 8pksci">.css-8pksci{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;z-index:0;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;}.css-8pksci::before{border-radius:2px;content:"";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-8pksci:active{background-color:transparent;}.css-8pksci:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-8pksci:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-8pksci:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-8pksci >*{z-index:1;}</style><a data-waffles-component="button" data-trackid="alpa-navbar-breadcrumb-learn" href="https://www.datacamp.com" itemprop="item" aria-label="Learn" class="css-8pksci"><span class="css-61bni1"><span itemprop="name">Learn</span></span></a><meta content="0" itemprop="position"></li><div aria-hidden="true">/</div><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a data-waffles-component="button" data-trackid="alpa-navbar-breadcrumb-courses" href="https://www.datacamp.com/category/python" itemprop="item" aria-label="Courses" class="css-8pksci"><span class="css-61bni1"><span itemprop="name">Courses</span></span></a><meta content="1" itemprop="position"></li><div aria-hidden="true">/</div><li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a data-waffles-component="button" data-trackid="alpa-navbar-breadcrumb-course" href="https://www.datacamp.com/courses/natural-language-processing-nlp-in-python" itemprop="item" aria-label="Natural Language Processing (NLP) in Python" class="css-8pksci"><span class="css-61bni1"><span itemprop="name">Natural Language Processing (NLP) in Python</span></span></a><meta content="2" itemprop="position"></li></ol></nav></div><style data-emotion="css 1jov1vc">.css-1jov1vc{-webkit-box-pack:initial;-ms-flex-pack:initial;-webkit-justify-content:initial;justify-content:initial;}</style><div class="css-1jov1vc"></div><style data-emotion="css r4fpqc">.css-r4fpqc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;}</style><nav class="css-r4fpqc"><style data-emotion="css 79elbk">.css-79elbk{position:relative;}</style><div class="css-79elbk"><style data-emotion="css 10ganm4">.css-10ganm4{border:none;}</style><style data-emotion="css orecl4">.css-orecl4{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;z-index:0;background-color:transparent;color:var(--wf-text--main, #05192D);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;border-color:var(--wf-border-color--interactive, rgba(48, 57, 105, 0.6));border:none;}.css-orecl4::before{border-radius:2px;content:"";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-orecl4::before{border-radius:2px;margin:0;}.css-orecl4:active{background-color:transparent;}.css-orecl4:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-orecl4:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-orecl4 >*{z-index:1;}</style><button data-waffles-component="button" class="css-orecl4" aria-label="course-menu" type="button"><span class="css-61bni1"><style data-emotion="css 6su6fj">.css-6su6fj{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}</style><svg aria-hidden="true" data-waffles-component="icon" height="16" width="16" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" d="M2 11a2 2 0 1 1 0-4 2 2 0 0 1 0 4Zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4Zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4Z"/></svg></span></button><style data-emotion="css h7pn2b">.css-h7pn2b{position:absolute;top:32px;right:0;padding:8px;padding-left:0;padding-right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:90dvw;z-index:5000;width:0;height:0;overflow:hidden;}.css-h7pn2b button span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;font-weight:400;width:100%;}</style><style data-emotion="css 1ydqvfl">.css-1ydqvfl{background-color:var(--wf-bg--contrast, #FFFFFF);border-color:var(--wf-border-color--main, rgba(48, 57, 105, 0.15));border-radius:4px;border-style:solid;border-width:1px;display:block;outline:0;padding:16px;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:box-shadow 600ms cubic-bezier(0.1, 0.8, 0.2, 1),-webkit-transform 600ms cubic-bezier(0.1, 0.8, 0.2, 1);transition:box-shadow 600ms cubic-bezier(0.1, 0.8, 0.2, 1),transform 600ms cubic-bezier(0.1, 0.8, 0.2, 1);position:absolute;top:32px;right:0;padding:8px;padding-left:0;padding-right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:90dvw;z-index:5000;width:0;height:0;overflow:hidden;}.css-1ydqvfl:where(a, button){cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}.css-1ydqvfl button span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;font-weight:400;width:100%;}</style><section data-waffles-component="card" aria-hidden="true" class="css-1ydqvfl"><nav><style data-emotion="css 15c08fe">.css-15c08fe{color:#05192D;border:none;width:100%;}@media screen and (min-width: 820px){.css-15c08fe{border-radius:0;}.css-15c08fe:after{border-radius:0;}}</style><style data-emotion="css r2fclv">.css-r2fclv{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;z-index:0;background-color:transparent;color:var(--wf-text--main, #05192D);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;border-color:var(--wf-border-color--interactive, rgba(48, 57, 105, 0.6));color:#05192D;border:none;width:100%;}.css-r2fclv::before{border-radius:2px;content:"";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-r2fclv::before{border-radius:2px;margin:0;}.css-r2fclv:active{background-color:transparent;}.css-r2fclv:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-r2fclv:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-r2fclv >*{z-index:1;}@media screen and (min-width: 820px){.css-r2fclv{border-radius:0;}.css-r2fclv:after{border-radius:0;}}</style><button data-waffles-component="button" data-cy="header-outline" class="css-r2fclv" type="button"><span class="css-61bni1"><svg aria-hidden="true" data-waffles-component="icon" height="16" width="16" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" d="M4 6a1 1 0 1 1 0-2h10a1 1 0 0 1 0 2H4Zm0 4a1 1 0 1 1 0-2h10a1 1 0 0 1 0 2H4Zm0 4a1 1 0 0 1 0-2h10a1 1 0 0 1 0 2H4Z"/></svg>Course Outline</span></button></nav><style data-emotion="css 16cuyl0">.css-16cuyl0{color:#05192D;}</style><style data-emotion="css 1h1hx0e">.css-1h1hx0e{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;z-index:0;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;color:#05192D;}.css-1h1hx0e::before{border-radius:2px;content:"";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-1h1hx0e:active{background-color:transparent;}.css-1h1hx0e:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-1h1hx0e:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-1h1hx0e:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-1h1hx0e >*{z-index:1;}</style><button data-waffles-component="button" data-cy="header-slides" class="css-1h1hx0e" type="button"><span class="css-61bni1"><svg aria-hidden="true" data-waffles-component="icon" height="14" width="14" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" d="M14 9.004H9.996a2 2 0 0 1-2-2V2H4v14h10V9.004Zm1.828-2.815A1.938 1.938 0 0 1 16 7v9a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V2a2 2 0 0 1 2-2h5.003a2 2 0 0 1 1.415.586l4.997 5a2 2 0 0 1 .413.603Zm-1.832.815-4-4v4h4Z"/></svg>Show slides</span></button><button data-waffles-component="button" data-cy="header-video" class="css-1h1hx0e" aria-label="Show video" type="button"><span class="css-61bni1"><svg aria-hidden="true" data-waffles-component="icon" height="14" width="14" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" d="m13 6.3 3.331-2.998A1 1 0 0 1 18 4.045v9.91a1 1 0 0 1-1.669.743L13 11.7V14c0 .552-.485 1-1.083 1H1.083C.485 15 0 14.552 0 14V4c0-.552.485-1 1.083-1h10.834C12.515 3 13 3.448 13 4v2.3Zm0 2.69v.02l3 2.7V6.29l-3 2.7ZM2 5v8h9V5H2Z"/></svg>Show video</span></button><button data-waffles-component="button" data-cy="header-notes" class="css-1h1hx0e" type="button"><span class="css-61bni1"><svg aria-hidden="true" data-waffles-component="icon" height="14" width="14" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" fill-rule="evenodd" clip-rule="evenodd" d="M12.528.293a.999.999 0 0 1 1.414 0l3.765 3.765a.999.999 0 0 1 0 1.414L5.472 17.707a1 1 0 0 1-.707.293H1a1 1 0 0 1-1-1v-3.765c0-.265.105-.52.293-.707L12.528.293zM2 13.65V16h2.35l8.412-8.412-2.35-2.35L2 13.65zm9.826-9.826 2.351 2.351 1.409-1.409-2.351-2.35-1.409 1.408zM16.529 18h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2z"/></svg>Take notes</span></button><button data-waffles-component="button" data-cy="header-mobile" class="css-1h1hx0e" type="button"><span class="css-61bni1"><svg aria-hidden="true" data-waffles-component="icon" height="14" width="14" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" d="M5.5 2v14h7V2h-7Zm-1-2h9a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1h-9a1 1 0 0 1-1-1V1a1 1 0 0 1 1-1Zm4 13h1a1 1 0 0 1 0 2h-1a1 1 0 0 1 0-2Z"/></svg>Continue learning on mobile</span></button><button data-waffles-component="button" data-cy="header-issue" data-test-id="header-report-issue-button" class="css-1h1hx0e" type="button"><span class="css-61bni1"><svg aria-hidden="true" data-waffles-component="icon" height="14" width="14" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" fill-rule="evenodd" clip-rule="evenodd" d="M17.744 14.31 10.869 1.647a2.119 2.119 0 0 0-3.72 0L.268 14.31a2.116 2.116 0 0 0 1.862 3.148h13.75A2.122 2.122 0 0 0 18 15.383a2.12 2.12 0 0 0-.256-1.052v-.021zm-2.054.419L9.448 3.24a.5.5 0 0 0-.879 0L2.322 14.73a.5.5 0 0 0 .439.739H15.25a.502.502 0 0 0 .44-.74zM8.02 7.017a.994.994 0 1 1 1.99 0v2.57a.994.994 0 1 1-1.99 0v-2.57zm1.021 6.961a1.144 1.144 0 0 1-1.054-.704 1.143 1.143 0 0 1 .247-1.243 1.14 1.14 0 0 1 1.947.807 1.14 1.14 0 0 1-1.14 1.14z"/></svg>Provide feedback</span></button><style data-emotion="css xqh66l">.css-xqh66l{margin:8px;color:#05192D;opacity:0.15;border-bottom:none;}</style><hr class="css-xqh66l"><style data-emotion="css yv011k">.css-yv011k{padding:8px;padding-left:16px;padding-right:16px;}</style><div class="css-yv011k"><div data-cy="header-session" css="[object Object]"><style data-emotion="css 8zmdb0">.css-8zmdb0{color:#03EF62;}</style><style data-emotion="css 1kziqvt">.css-1kziqvt{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;color:#03EF62;}</style><svg aria-hidden="true" data-waffles-component="icon" height="16" width="16" viewbox="0 0 18 18" aria-label="Session Ready" class="css-1kziqvt"><path fill="currentColor" d="M9 18A9 9 0 1 1 9 0a9 9 0 0 1 0 18Z"/></svg><style data-emotion="css 1isemmb">.css-1isemmb{margin-left:8px;}</style><span data-waffles-component="text" class="css-1isemmb">Connected</span></div></div></section></div></nav></header><style data-emotion="css iqa0tj">.css-iqa0tj{position:absolute;top:100px;bottom:32px;right:12px;left:12px;overflow:hidden;}</style><main class="css-iqa0tj"><div data-cy="server-side-loader-placeholder"><aside class="exercise--sidebar" style="width:40%"><style data-emotion="css 1an29gy">.css-1an29gy{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;height:100%;overflow-y:hidden;}</style><div class="exercise--sidebar-content css-1an29gy"><style data-emotion="css 16awsaw">.css-16awsaw{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;overflow-y:auto;}</style><div class="css-16awsaw"><div class="listview__outer"><div class="listview__inner"><div class="listview__section"><div><div role="button" class="listview__header"><style data-emotion="css r7m65a">.css-r7m65a{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;padding-right:16px;}</style><div class="css-r7m65a"><style data-emotion="css 171fln0">.css-171fln0{font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><style data-emotion="css 10nfsoz">.css-10nfsoz{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><style data-emotion="css 1tah88q">.css-1tah88q{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><h2 data-waffles-component="heading" class="css-1tah88q"><style data-emotion="css 6su6fj">.css-6su6fj{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;}</style><svg aria-hidden="true" data-waffles-component="icon" height="14" width="14" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" d="M4 2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h10a1 1 0 0 0 1-1V3a1 1 0 0 0-1-1H4Zm0-2h10a3 3 0 0 1 3 3v12a3 3 0 0 1-3 3H4a3 3 0 0 1-3-3V3a3 3 0 0 1 3-3Zm2 6h6a1 1 0 0 1 0 2H6a1 1 0 1 1 0-2Zm0 4h6a1 1 0 0 1 0 2H6a1 1 0 0 1 0-2Z"/></svg>Exercise</h2></div></div></div><div class="listview__content"><style data-emotion="css ikv0qb">.css-ikv0qb{position:relative;padding:16px;}</style><div class="css-ikv0qb"><style data-emotion="css 1c1rk5o">.css-1c1rk5o{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:20px;}</style><style data-emotion="css fsa3o0">.css-fsa3o0{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:20px;}</style><h1 data-waffles-component="heading" class="css-fsa3o0">Analyzing the sentiment of a review</h1><style data-emotion="css 8czf7d">.css-8czf7d{line-height:1.5;}.css-8czf7d code{font-family:JetBrainsMonoNL,Menlo,Monaco,'Courier New',monospace;margin:0 2px;padding:2px 4px;line-height:1.25;background-color:#EFEFF5;border-radius:4px;font-size:86%;mix-blend-mode:multiply;}.css-8czf7d pre{background-color:#EFEFF5;padding:8px;margin:0;border-radius:4px;tab-size:4;white-space:pre;line-height:1.25;mix-blend-mode:multiply;}.css-8czf7d pre>code{margin:0;padding:0;background-color:transparent;}.css-8czf7d ul,.css-8czf7d ol{padding-left:16px;}.css-8czf7d ul:first-of-type,.css-8czf7d ol:first-of-type{margin-top:0;}.css-8czf7d p:first-of-type{margin-top:0;}.css-8czf7d li{margin-bottom:8px;}.css-8czf7d a{color:#0065D1;-webkit-text-decoration:none;text-decoration:none;font-weight:800;border-radius:4px;outline:0;}.css-8czf7d a:hover{color:#0065D1;-webkit-text-decoration:underline;text-decoration:underline;}.css-8czf7d a:focus-visible{box-shadow:0 0 0 2px #257DFE;}.css-8czf7d a code{color:#0065D1;}.css-8czf7d hr{background-color:rgba(48, 57, 105, 0.15);border:0;height:1px;margin:16px 0;}</style><style data-emotion="css alxior">.css-alxior{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;line-height:1.5;}.css-alxior code{font-family:JetBrainsMonoNL,Menlo,Monaco,'Courier New',monospace;margin:0 2px;padding:2px 4px;line-height:1.25;background-color:#EFEFF5;border-radius:4px;font-size:86%;mix-blend-mode:multiply;}.css-alxior pre{background-color:#EFEFF5;padding:8px;margin:0;border-radius:4px;tab-size:4;white-space:pre;line-height:1.25;mix-blend-mode:multiply;}.css-alxior pre>code{margin:0;padding:0;background-color:transparent;}.css-alxior ul,.css-alxior ol{padding-left:16px;}.css-alxior ul:first-of-type,.css-alxior ol:first-of-type{margin-top:0;}.css-alxior p:first-of-type{margin-top:0;}.css-alxior li{margin-bottom:8px;}.css-alxior a{color:#0065D1;-webkit-text-decoration:none;text-decoration:none;font-weight:800;border-radius:4px;outline:0;}.css-alxior a:hover{color:#0065D1;-webkit-text-decoration:underline;text-decoration:underline;}.css-alxior a:focus-visible{box-shadow:0 0 0 2px #257DFE;}.css-alxior a code{color:#0065D1;}.css-alxior hr{background-color:rgba(48, 57, 105, 0.15);border:0;height:1px;margin:16px 0;}</style><div data-waffles-component="text" class="css-alxior"><div class><p>Your team is building a tool to monitor customer sentiment in product reviews. As a first step, you&apos;re testing the sentiment of individual reviews using a pre-trained pipeline.</p></div></div></div></div></div><div class="listview__section" style="min-height:calc(50% - 33px)"><div><div role="button" class="listview__header"><div class="css-r7m65a"><style data-emotion="css 1ubtfgv">.css-1ubtfgv{font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><style data-emotion="css ycumlt">.css-ycumlt{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><style data-emotion="css 1kphf8n">.css-1kphf8n{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><h2 data-waffles-component="heading" class="css-1kphf8n"><svg aria-hidden="true" data-waffles-component="icon" height="14" width="14" viewbox="0 0 18 18" class="css-6su6fj"><path fill="currentColor" d="M9 16A7 7 0 1 0 9 2a7 7 0 0 0 0 14Zm0 2A9 9 0 1 1 9 0a9 9 0 0 1 0 18Zm2.326-11.96a1 1 0 0 1 1.555 1.258L8.773 12.37a1 1 0 0 1-1.534.024l-2.124-2.46a1 1 0 0 1 1.514-1.307l1.342 1.556 3.355-4.144Z"/></svg>Instructions</h2><style data-emotion="css 17lebkx">.css-17lebkx{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-17lebkx span{color:var(--wf-yellow--text-on-color, #05192D);}</style><style data-emotion="css 1gjxyd4">.css-1gjxyd4{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-1gjxyd4 span{color:var(--wf-yellow--text-on-color, #05192D);}</style><span data-waffles-component="badge" class="css-1gjxyd4"><style data-emotion="css 19ist84">.css-19ist84{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:inherit;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;gap:4px;max-width:164px;}</style><span class="css-19ist84"><style data-emotion="css 8uhtka">.css-8uhtka{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}</style><span class="css-8uhtka">100 XP</span></span></span></div></div></div><div class="listview__content"><div><style data-emotion="css 186pnwx">.css-186pnwx{-webkit-flex:1;-ms-flex:1;flex:1;position:relative;padding:16px;}</style><div class="css-186pnwx"><div data-waffles-component="text" class="css-alxior"><div class="exercise--instructions__content"><ul>
<li>Initialize a <code>pipeline</code> for <code>sentiment-analysis</code> with the <code>&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</code> model.</li>
<li>Use the <code>pipeline</code> to classify the sentiment of <code>review_text</code>.</li>
</ul></div></div><style data-emotion="css kbabwt">.css-kbabwt{margin:16px -16px 0;}</style><div class="css-kbabwt"><section class="dc-sct-feedback" tabindex="-1"><div></div><nav class="dc-sct-feedback__nav"><style data-emotion="css n085mf">.css-n085mf{padding-left:16px;}</style><div class="css-n085mf"><style data-emotion="css 12j1yck">.css-12j1yck{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;-webkit-text-decoration:none;text-decoration:none;text-transform:capitalize;-webkit-transition:0.15s;transition:0.15s;vertical-align:baseline;white-space:nowrap;background-color:transparent;border-color:#05192D;color:#05192D;padding:0 15px;}.css-12j1yck:active{-webkit-transform:perspective(1px) scale(0.975);-moz-transform:perspective(1px) scale(0.975);-ms-transform:perspective(1px) scale(0.975);transform:perspective(1px) scale(0.975);}.css-12j1yck:disabled,.css-12j1yck:hover:disabled,.css-12j1yck:active:disabled{-webkit-transform:none;-moz-transform:none;-ms-transform:none;transform:none;}.css-12j1yck:focus{outline:0;}.css-12j1yck:hover{background-color:rgba(5, 25, 45, 0.15);border-color:#05192D;color:#05192D;}</style><button class="dc-sct-feedback__nav--hint-solution css-12j1yck" type="button" data-cy="exercise-show-hint"><svg viewbox="0 0 18 18" aria-hidden="true" height="16" role="img" width="16"><path fill="currentColor" d="M9 0a7 7 0 014.95 11.95l-.001-.001c-.794.795-.949 1.1-.949 2.051a1 1 0 01-2 0c0-1.548.396-2.325 1.535-3.467l.04-.037a5 5 0 10-7.11.037C6.605 11.675 7 12.453 7 14a1 1 0 01-2 0c0-.951-.155-1.256-.949-2.051A7 7 0 019 0zm0 7a1 1 0 011 1v6a1 1 0 01-2 0V8a1 1 0 011-1zm0 11c-1.657 0-3-.895-3-2h6c0 1.105-1.343 2-3 2z" fill-rule="evenodd"/></svg><style data-emotion="css aib9ji">.css-aib9ji{font-size:14px;line-height:32px;color:#05192D;font-weight:bold;margin-left:8px;}</style><style data-emotion="css vvk465">.css-vvk465{-webkit-font-smoothing:antialiased;color:#05192D;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-style:normal;font-size:14px;font-weight:400;font-size:14px;line-height:32px;color:#05192D;font-weight:bold;margin-left:8px;}</style><span class="css-vvk465">Take Hint (-30 XP)</span></button></div></nav></section></div></div></div></div></div></div></div></div></div></aside><section class="exercise--content" style="width:60%"><div class="exercise-waiting"><style data-emotion="css 1gnr744">.css-1gnr744{position:absolute;top:50%;left:50%;-webkit-transform:translate(-50%, -50%);-moz-transform:translate(-50%, -50%);-ms-transform:translate(-50%, -50%);transform:translate(-50%, -50%);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}</style><div class="css-1gnr744"><style data-emotion="css 1rm9ybb animation-1pv1bkr">.css-1rm9ybb{-webkit-animation:animation-1pv1bkr cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;animation:animation-1pv1bkr cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;will-change:clip-path;--wf-loader--color:var(--wf-text--main, #05192D);width:50;}@-webkit-keyframes animation-1pv1bkr{0%,6%{-webkit-clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);}100%{-webkit-clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);}}@keyframes animation-1pv1bkr{0%,6%{-webkit-clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);}100%{-webkit-clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);}}</style><div aria-label="Loading" data-testid="loader-wrapper" role="alert" class="css-1rm9ybb"><style data-emotion="css 1j8nxo animation-1h2cwi2">.css-1j8nxo{-webkit-animation:animation-1h2cwi2 cubic-bezier(0, 0, 0.85, 1) 2s infinite alternate;animation:animation-1h2cwi2 cubic-bezier(0, 0, 0.85, 1) 2s infinite alternate;will-change:clip-path;}@-webkit-keyframes animation-1h2cwi2{0%,71%{-webkit-clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);}96%,100%{-webkit-clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);}}@keyframes animation-1h2cwi2{0%,71%{-webkit-clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);}96%,100%{-webkit-clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);}}</style><div class="css-1j8nxo"><style data-emotion="css zsjzbc">.css-zsjzbc{-webkit-clip-path:polygon(-0.1% -10%, 169% 65%, -0.1% 139%);clip-path:polygon(-0.1% -10%, 169% 65%, -0.1% 139%);}</style><div class="css-zsjzbc"><style data-emotion="css cihpzr">.css-cihpzr{display:block;overflow:visible;stroke:var(--wf-loader--color, var(--wf-text--main, #05192D));}</style><svg viewbox="0 0 2640 3444" data-waffles-component="loader" width="50" class="css-cihpzr"><style data-emotion="css jy99qt animation-co7x2c">.css-jy99qt{-webkit-animation:animation-co7x2c cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;animation:animation-co7x2c cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;stroke-dasharray:9800;stroke-dashoffset:9800;will-change:stroke-dashoffset;}@-webkit-keyframes animation-co7x2c{100%{stroke-dashoffset:0;}}@keyframes animation-co7x2c{100%{stroke-dashoffset:0;}}</style><path d="M0 0 M2569 1056L143 2447V149l1175 673v1867l1248 715" fill="none" stroke-linejoin="round" stroke-width="300" class="css-jy99qt"/></svg></div></div></div></div><noscript></noscript></div></section></div></main><div class="exercise-footer"><style data-emotion="css 8uttuf">.css-8uttuf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;width:100%;max-width:600px;list-style:none;margin:0;padding:0;gap:8px;}</style><ul data-cy="progress-container" class="css-8uttuf"><style data-emotion="css 149stfi">.css-149stfi{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;max-width:100px;}</style><li class="css-149stfi"><style data-emotion="css 46tute">.css-46tute{display:block;height:8px;border-radius:4px;background-color:rgba(48, 57, 105, 0.15);border-bottom:0;outline:0;}.css-46tute:focus-visible{box-shadow:0 0 0 2px #257DFE;}</style><a href="javascript:void(0)" data-testid="progress-indicator-item" class="css-46tute"><style data-emotion="css 1pw8nbl">.css-1pw8nbl{-webkit-transition:width 250ms linear;transition:width 250ms linear;height:8px;border-radius:4px;background-color:#5EB1FF;}</style><div style="width:0%" class="css-1pw8nbl"></div></a></li><li class="css-149stfi"><a href="javascript:void(0)" data-testid="progress-indicator-item" class="css-46tute"><div style="width:0%" class="css-1pw8nbl"></div></a></li><li class="css-149stfi"><a href="javascript:void(0)" data-testid="progress-indicator-item" class="css-46tute"><div style="width:0%" class="css-1pw8nbl"></div></a></li><li class="css-149stfi"><a href="javascript:void(0)" data-testid="progress-indicator-item" class="css-46tute"><div style="width:0%" class="css-1pw8nbl"></div></a></li></ul></div></div></div><script>window.MathJax={options:{ignoreHtmlClass:"tex2jax_ignore",processHtmlClass:"tex2jax_process"},tex:{autoload:{color:[],colorV2:["color"]},packages:{"[+]":["noerrors"]}},loader:{load:["[tex]/noerrors"]}}</script><script src="/campus/mathjax@3/es5/tex-chtml.js" id="MathJax-script" async></script><script>!function(e){function c(c){for(var f,o,s=c[0],b=c[1],r=c[2],m=0,t=[];m<s.length;m++)o=s[m],Object.prototype.hasOwnProperty.call(a,o)&&a[o]&&t.push(a[o][0]),a[o]=0;for(f in b)Object.prototype.hasOwnProperty.call(b,f)&&(e[f]=b[f]);for(v&&v(c);t.length;)t.shift()();return n.push.apply(n,r||[]),d()}function d(){for(var e,c=0;c<n.length;c++){for(var d=n[c],f=!0,o=1;o<d.length;o++){var b=d[o];0!==a[b]&&(f=!1)}f&&(n.splice(c--,1),e=s(s.s=d[0]))}return e}var f={},o={175:0},a={175:0},n=[];function s(c){if(f[c])return f[c].exports;var d=f[c]={i:c,l:!1,exports:{}};return e[c].call(d.exports,d,d.exports,s),d.l=!0,d.exports}s.e=function(e){var c=[];o[e]?c.push(o[e]):0!==o[e]&&{5:1,6:1,9:1,13:1,14:1,15:1,16:1,20:1,22:1,25:1,27:1,30:1,31:1,35:1,37:1,40:1,41:1,42:1,44:1,45:1,49:1,51:1,53:1,57:1,59:1,62:1,80:1,84:1,88:1,91:1,94:1,95:1,96:1,99:1,100:1,105:1,107:1,109:1,112:1,114:1,117:1,118:1,133:1,135:1,138:1,139:1,140:1,142:1,143:1,148:1,150:1,152:1,156:1,158:1,161:1,163:1,233:1,239:1,241:1,247:1,248:1,249:1,252:1,253:1,254:1,256:1}[e]&&c.push(o[e]=new Promise((function(c,d){for(var f="static/css/"+({0:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~se~ve~vise~a4f7b5e1",1:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~splitio~ve~vise~253ae210",2:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~splitio~ve~vise~c7ce39a9",3:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~splitio~ve~vise~d49b3b41",4:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~ve~vise~253ae210",5:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pmce~vise~253ae210",6:"vendors~console-monaco~monaco~1c28f7ca",7:"vendors~console-monaco~monaco~235b8c57",8:"vendors~console-monaco~monaco~253ae210",9:"vendors~console-monaco~monaco~36912834",10:"vendors~console-monaco~monaco~49d8ad03",11:"vendors~console-monaco~monaco~4d911f2e",12:"vendors~console-monaco~monaco~5584ff6c",13:"vendors~console-monaco~monaco~57c220dc",14:"vendors~console-monaco~monaco~589039fc",15:"vendors~console-monaco~monaco~5e1bc0de",16:"vendors~console-monaco~monaco~6ddf31e8",17:"vendors~console-monaco~monaco~80993005",18:"vendors~console-monaco~monaco~85a20469",19:"vendors~console-monaco~monaco~86ffeb1a",20:"vendors~console-monaco~monaco~900aca88",21:"vendors~console-monaco~monaco~9c5b28f6",22:"vendors~console-monaco~monaco~a03ee73f",23:"vendors~console-monaco~monaco~ba2d52b5",24:"vendors~console-monaco~monaco~c01cf258",25:"vendors~console-monaco~monaco~c682183c",26:"vendors~console-monaco~monaco~c73e0090",27:"vendors~console-monaco~monaco~d7ac9e7b",28:"vendors~console-monaco~monaco~dac6e39f",29:"vendors~console-monaco~monaco~e66ff6d3",30:"vendors~console-monaco~monaco~e69ef85d",31:"vendors~console-monaco~monaco~f7d19227",33:"afce~06694820",34:"afce~0f485567",35:"afce~1c28f7ca",36:"afce~235b8c57",37:"afce~36912834",38:"afce~4d911f2e",39:"afce~5584ff6c",40:"afce~57c220dc",41:"afce~589039fc",42:"afce~5e1bc0de",43:"afce~65e15191",44:"afce~690b702c",45:"afce~6ddf31e8",46:"afce~80993005",47:"afce~85a20469",48:"afce~86ffeb1a",49:"afce~900aca88",50:"afce~9c5b28f6",51:"afce~a03ee73f",52:"afce~b4cc8fed",53:"afce~b6351802",54:"afce~ba2d52b5",55:"afce~c01cf258",56:"afce~c09866d3",57:"afce~c682183c",58:"afce~c73e0090",59:"afce~d7ac9e7b",60:"afce~dac6e39f",61:"afce~e66ff6d3",62:"afce~f7d19227",63:"ce~00b78636",64:"ce~253ae210",65:"ce~4b4fcabe",66:"ce~4e8588b8",67:"ce~748942c6",68:"ce~a4f7b5e1",69:"ce~b5a0571e",70:"ce~cec4ba35",71:"ce~e65503b9",72:"ce~eefe6aba",73:"ce~f9ca8911",74:"console-monaco~31ecd969",75:"dle~06694820",76:"dle~0f485567",77:"dle~545f53ec",78:"dle~9779364a",79:"dle~b9cf3951",80:"dnde~253ae210",81:"dnde~9c5b28f6",82:"dnde~c8f69aa9",83:"ee~253ae210",84:"ee~a4f7b5e1",85:"ee~eefe6aba",86:"ge~06694820",87:"ge~0f485567",88:"ge~1c28f7ca",89:"ge~235b8c57",90:"ge~253ae210",91:"ge~36912834",92:"ge~4d911f2e",93:"ge~5584ff6c",94:"ge~57c220dc",95:"ge~589039fc",96:"ge~5e1bc0de",97:"ge~645e357e",98:"ge~65e15191",99:"ge~6ddf31e8",100:"ge~7c919857",101:"ge~80993005",102:"ge~82be2ce2",103:"ge~85a20469",104:"ge~86ffeb1a",105:"ge~900aca88",106:"ge~9c5b28f6",107:"ge~a03ee73f",108:"ge~b4cc8fed",109:"ge~b6351802",110:"ge~ba2d52b5",111:"ge~c01cf258",112:"ge~c682183c",113:"ge~c73e0090",114:"ge~d7ac9e7b",115:"ge~dac6e39f",116:"ge~e66ff6d3",117:"ge~f7d19227",118:"idee~0f485567",119:"idee~7274e1de",120:"idee~eefe6aba",128:"markdown-renderer~2353b14b",129:"modal-views~31ecd969",130:"monaco~31ecd969",131:"msce~06694820",132:"msce~0f485567",133:"msce~1c28f7ca",134:"msce~235b8c57",135:"msce~36912834",136:"msce~4d911f2e",137:"msce~5584ff6c",138:"msce~57c220dc",139:"msce~589039fc",140:"msce~5e1bc0de",141:"msce~65e15191",142:"msce~690b702c",143:"msce~6ddf31e8",144:"msce~781ea4ba",145:"msce~80993005",146:"msce~85a20469",147:"msce~86ffeb1a",148:"msce~900aca88",149:"msce~9c5b28f6",150:"msce~a03ee73f",151:"msce~b4cc8fed",152:"msce~b6351802",153:"msce~ba2d52b5",154:"msce~c01cf258",155:"msce~c09866d3",156:"msce~c682183c",157:"msce~c73e0090",158:"msce~d7ac9e7b",159:"msce~dac6e39f",160:"msce~e66ff6d3",161:"msce~f7d19227",162:"pmce~06694820",163:"pmce~0f485567",164:"pmce~55203cfd",165:"pmce~56e1be11",166:"pmce~678f84af",167:"pmce~980718ed",168:"pmce~a4f7b5e1",169:"pmce~c59e43b8",170:"pmce~ce5883b0",171:"pmce~d80adb5f",172:"pmce~d939e436",173:"pmce~ee846d98",174:"rde~3333b9b6",216:"vendors~pe~06694820",217:"vendors~pe~0f485567",218:"vendors~pe~55203cfd",219:"vendors~pe~678f84af",220:"vendors~pe~690b702c",221:"vendors~pe~71125b46",222:"vendors~pe~777db305",223:"vendors~pe~82854e37",224:"vendors~pe~8b9d99e7",225:"vendors~pe~9321a7ba",226:"vendors~pe~c59e43b8",227:"vendors~pe~d4945f69",228:"vendors~pe~d80adb5f",229:"vendors~pe~d939e436",230:"vendors~pe~ee846d98",231:"vendors~pe~fc6deeec",232:"vendors~phe~ce5883b0",233:"vendors~phe~eefe6aba",234:"vendors~rde~0f485567",235:"vendors~rde~253ae210",236:"vendors~rde~37904b70",237:"vendors~rde~4e8588b8",238:"vendors~rde~7274e1de",239:"vendors~rde~82be2ce2",240:"vendors~rde~88436a7c",241:"vendors~rde~922e58ef",242:"vendors~rde~b24a28be",243:"vendors~rde~b5a0571e",244:"vendors~rde~cec4ba35",245:"vendors~rde~cf3d4a10",246:"vendors~rde~e65503b9",247:"vendors~rde~f9ca8911",248:"vendors~se~9774f63b",249:"vendors~se~a4f7b5e1",250:"vendors~se~d0fcca00",251:"vendors~ve~2374ce8c",252:"vendors~ve~305045fd",253:"vendors~ve~82be2ce2",254:"vendors~ve~ab8235e0",255:"vendors~ve~cfba5e8d",256:"vendors~xterm~0d30e071",257:"vise~cfba5e8d",258:"vise~da250ca5",259:"vise~e65503b9",260:"xterm~d021be4b"}[e]||e)+"."+{0:"31d6cfe0",1:"31d6cfe0",2:"31d6cfe0",3:"31d6cfe0",4:"31d6cfe0",5:"f479e7a2",6:"5be0a39a",7:"31d6cfe0",8:"31d6cfe0",9:"1ad26591",10:"31d6cfe0",11:"31d6cfe0",12:"31d6cfe0",13:"ea109276",14:"59e05191",15:"9bf089b3",16:"d2c4604b",17:"31d6cfe0",18:"31d6cfe0",19:"31d6cfe0",20:"f9fdab18",21:"31d6cfe0",22:"98d862d2",23:"31d6cfe0",24:"31d6cfe0",25:"03248981",26:"31d6cfe0",27:"9f101993",28:"31d6cfe0",29:"31d6cfe0",30:"3f1ff7c1",31:"2281ed76",32:"31d6cfe0",33:"31d6cfe0",34:"31d6cfe0",35:"5be0a39a",36:"31d6cfe0",37:"1ad26591",38:"31d6cfe0",39:"31d6cfe0",40:"ea109276",41:"59e05191",42:"9bf089b3",43:"31d6cfe0",44:"96a878eb",45:"d2c4604b",46:"31d6cfe0",47:"31d6cfe0",48:"31d6cfe0",49:"f9fdab18",50:"31d6cfe0",51:"98d862d2",52:"31d6cfe0",53:"28103d70",54:"31d6cfe0",55:"31d6cfe0",56:"31d6cfe0",57:"03248981",58:"31d6cfe0",59:"9f101993",60:"31d6cfe0",61:"31d6cfe0",62:"2281ed76",63:"31d6cfe0",64:"31d6cfe0",65:"31d6cfe0",66:"31d6cfe0",67:"31d6cfe0",68:"31d6cfe0",69:"31d6cfe0",70:"31d6cfe0",71:"31d6cfe0",72:"31d6cfe0",73:"31d6cfe0",74:"31d6cfe0",75:"31d6cfe0",76:"31d6cfe0",77:"31d6cfe0",78:"31d6cfe0",79:"31d6cfe0",80:"f63aa94e",81:"31d6cfe0",82:"31d6cfe0",83:"31d6cfe0",84:"318451f9",85:"31d6cfe0",86:"31d6cfe0",87:"31d6cfe0",88:"5be0a39a",89:"31d6cfe0",90:"31d6cfe0",91:"1ad26591",92:"31d6cfe0",93:"31d6cfe0",94:"ea109276",95:"59e05191",96:"9bf089b3",97:"31d6cfe0",98:"31d6cfe0",99:"d2c4604b",100:"96a878eb",101:"31d6cfe0",102:"31d6cfe0",103:"31d6cfe0",104:"31d6cfe0",105:"f9fdab18",106:"31d6cfe0",107:"98d862d2",108:"31d6cfe0",109:"28103d70",110:"31d6cfe0",111:"31d6cfe0",112:"03248981",113:"31d6cfe0",114:"9f101993",115:"31d6cfe0",116:"31d6cfe0",117:"2281ed76",118:"c86e1775",119:"31d6cfe0",120:"31d6cfe0",128:"31d6cfe0",129:"31d6cfe0",130:"31d6cfe0",131:"31d6cfe0",132:"31d6cfe0",133:"5be0a39a",134:"31d6cfe0",135:"1ad26591",136:"31d6cfe0",137:"31d6cfe0",138:"ea109276",139:"59e05191",140:"9bf089b3",141:"31d6cfe0",142:"96a878eb",143:"d2c4604b",144:"31d6cfe0",145:"31d6cfe0",146:"31d6cfe0",147:"31d6cfe0",148:"f9fdab18",149:"31d6cfe0",150:"98d862d2",151:"31d6cfe0",152:"28103d70",153:"31d6cfe0",154:"31d6cfe0",155:"31d6cfe0",156:"03248981",157:"31d6cfe0",158:"9f101993",159:"31d6cfe0",160:"31d6cfe0",161:"2281ed76",162:"31d6cfe0",163:"5f802060",164:"31d6cfe0",165:"31d6cfe0",166:"31d6cfe0",167:"31d6cfe0",168:"31d6cfe0",169:"31d6cfe0",170:"31d6cfe0",171:"31d6cfe0",172:"31d6cfe0",173:"31d6cfe0",174:"31d6cfe0",216:"31d6cfe0",217:"31d6cfe0",218:"31d6cfe0",219:"31d6cfe0",220:"31d6cfe0",221:"31d6cfe0",222:"31d6cfe0",223:"31d6cfe0",224:"31d6cfe0",225:"31d6cfe0",226:"31d6cfe0",227:"31d6cfe0",228:"31d6cfe0",229:"31d6cfe0",230:"31d6cfe0",231:"31d6cfe0",232:"31d6cfe0",233:"f479e7a2",234:"31d6cfe0",235:"31d6cfe0",236:"31d6cfe0",237:"31d6cfe0",238:"31d6cfe0",239:"cb178535",240:"31d6cfe0",241:"05896465",242:"31d6cfe0",243:"31d6cfe0",244:"31d6cfe0",245:"31d6cfe0",246:"31d6cfe0",247:"0cc5eb29",248:"2653f2ee",249:"f479e7a2",250:"31d6cfe0",251:"31d6cfe0",252:"0d471627",253:"f479e7a2",254:"2d3d39ad",255:"31d6cfe0",256:"9e71d144",257:"31d6cfe0",258:"31d6cfe0",259:"31d6cfe0",260:"31d6cfe0",261:"31d6cfe0",262:"31d6cfe0",263:"31d6cfe0",264:"31d6cfe0",265:"31d6cfe0",266:"31d6cfe0",267:"31d6cfe0",268:"31d6cfe0",269:"31d6cfe0",270:"31d6cfe0"}[e]+".chunk.css",a=s.p+f,n=document.getElementsByTagName("link"),b=0;b<n.length;b++){var r=(v=n[b]).getAttribute("data-href")||v.getAttribute("href");if("stylesheet"===v.rel&&(r===f||r===a))return c()}var m=document.getElementsByTagName("style");for(b=0;b<m.length;b++){var v;if((r=(v=m[b]).getAttribute("data-href"))===f||r===a)return c()}var t=document.createElement("link");t.rel="stylesheet",t.type="text/css",t.onload=c,t.onerror=function(c){var f=c&&c.target&&c.target.src||a,n=new Error("Loading CSS chunk "+e+" failed.\n("+f+")");n.code="CSS_CHUNK_LOAD_FAILED",n.request=f,delete o[e],t.parentNode.removeChild(t),d(n)},t.href=a,document.getElementsByTagName("head")[0].appendChild(t)})).then((function(){o[e]=0})));var d=a[e];if(0!==d)if(d)c.push(d[2]);else{var f=new Promise((function(c,f){d=a[e]=[c,f]}));c.push(d[2]=f);var n,b=document.createElement("script");b.charset="utf-8",b.timeout=120,s.nc&&b.setAttribute("nonce",s.nc),b.src=function(e){return s.p+"static/js/"+({0:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~se~ve~vise~a4f7b5e1",1:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~splitio~ve~vise~253ae210",2:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~splitio~ve~vise~c7ce39a9",3:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~splitio~ve~vise~d49b3b41",4:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pe~phe~pmce~rde~ve~vise~253ae210",5:"vendors~afce~ce~dle~dnde~ee~ge~idee~msce~pmce~vise~253ae210",6:"vendors~console-monaco~monaco~1c28f7ca",7:"vendors~console-monaco~monaco~235b8c57",8:"vendors~console-monaco~monaco~253ae210",9:"vendors~console-monaco~monaco~36912834",10:"vendors~console-monaco~monaco~49d8ad03",11:"vendors~console-monaco~monaco~4d911f2e",12:"vendors~console-monaco~monaco~5584ff6c",13:"vendors~console-monaco~monaco~57c220dc",14:"vendors~console-monaco~monaco~589039fc",15:"vendors~console-monaco~monaco~5e1bc0de",16:"vendors~console-monaco~monaco~6ddf31e8",17:"vendors~console-monaco~monaco~80993005",18:"vendors~console-monaco~monaco~85a20469",19:"vendors~console-monaco~monaco~86ffeb1a",20:"vendors~console-monaco~monaco~900aca88",21:"vendors~console-monaco~monaco~9c5b28f6",22:"vendors~console-monaco~monaco~a03ee73f",23:"vendors~console-monaco~monaco~ba2d52b5",24:"vendors~console-monaco~monaco~c01cf258",25:"vendors~console-monaco~monaco~c682183c",26:"vendors~console-monaco~monaco~c73e0090",27:"vendors~console-monaco~monaco~d7ac9e7b",28:"vendors~console-monaco~monaco~dac6e39f",29:"vendors~console-monaco~monaco~e66ff6d3",30:"vendors~console-monaco~monaco~e69ef85d",31:"vendors~console-monaco~monaco~f7d19227",33:"afce~06694820",34:"afce~0f485567",35:"afce~1c28f7ca",36:"afce~235b8c57",37:"afce~36912834",38:"afce~4d911f2e",39:"afce~5584ff6c",40:"afce~57c220dc",41:"afce~589039fc",42:"afce~5e1bc0de",43:"afce~65e15191",44:"afce~690b702c",45:"afce~6ddf31e8",46:"afce~80993005",47:"afce~85a20469",48:"afce~86ffeb1a",49:"afce~900aca88",50:"afce~9c5b28f6",51:"afce~a03ee73f",52:"afce~b4cc8fed",53:"afce~b6351802",54:"afce~ba2d52b5",55:"afce~c01cf258",56:"afce~c09866d3",57:"afce~c682183c",58:"afce~c73e0090",59:"afce~d7ac9e7b",60:"afce~dac6e39f",61:"afce~e66ff6d3",62:"afce~f7d19227",63:"ce~00b78636",64:"ce~253ae210",65:"ce~4b4fcabe",66:"ce~4e8588b8",67:"ce~748942c6",68:"ce~a4f7b5e1",69:"ce~b5a0571e",70:"ce~cec4ba35",71:"ce~e65503b9",72:"ce~eefe6aba",73:"ce~f9ca8911",74:"console-monaco~31ecd969",75:"dle~06694820",76:"dle~0f485567",77:"dle~545f53ec",78:"dle~9779364a",79:"dle~b9cf3951",80:"dnde~253ae210",81:"dnde~9c5b28f6",82:"dnde~c8f69aa9",83:"ee~253ae210",84:"ee~a4f7b5e1",85:"ee~eefe6aba",86:"ge~06694820",87:"ge~0f485567",88:"ge~1c28f7ca",89:"ge~235b8c57",90:"ge~253ae210",91:"ge~36912834",92:"ge~4d911f2e",93:"ge~5584ff6c",94:"ge~57c220dc",95:"ge~589039fc",96:"ge~5e1bc0de",97:"ge~645e357e",98:"ge~65e15191",99:"ge~6ddf31e8",100:"ge~7c919857",101:"ge~80993005",102:"ge~82be2ce2",103:"ge~85a20469",104:"ge~86ffeb1a",105:"ge~900aca88",106:"ge~9c5b28f6",107:"ge~a03ee73f",108:"ge~b4cc8fed",109:"ge~b6351802",110:"ge~ba2d52b5",111:"ge~c01cf258",112:"ge~c682183c",113:"ge~c73e0090",114:"ge~d7ac9e7b",115:"ge~dac6e39f",116:"ge~e66ff6d3",117:"ge~f7d19227",118:"idee~0f485567",119:"idee~7274e1de",120:"idee~eefe6aba",128:"markdown-renderer~2353b14b",129:"modal-views~31ecd969",130:"monaco~31ecd969",131:"msce~06694820",132:"msce~0f485567",133:"msce~1c28f7ca",134:"msce~235b8c57",135:"msce~36912834",136:"msce~4d911f2e",137:"msce~5584ff6c",138:"msce~57c220dc",139:"msce~589039fc",140:"msce~5e1bc0de",141:"msce~65e15191",142:"msce~690b702c",143:"msce~6ddf31e8",144:"msce~781ea4ba",145:"msce~80993005",146:"msce~85a20469",147:"msce~86ffeb1a",148:"msce~900aca88",149:"msce~9c5b28f6",150:"msce~a03ee73f",151:"msce~b4cc8fed",152:"msce~b6351802",153:"msce~ba2d52b5",154:"msce~c01cf258",155:"msce~c09866d3",156:"msce~c682183c",157:"msce~c73e0090",158:"msce~d7ac9e7b",159:"msce~dac6e39f",160:"msce~e66ff6d3",161:"msce~f7d19227",162:"pmce~06694820",163:"pmce~0f485567",164:"pmce~55203cfd",165:"pmce~56e1be11",166:"pmce~678f84af",167:"pmce~980718ed",168:"pmce~a4f7b5e1",169:"pmce~c59e43b8",170:"pmce~ce5883b0",171:"pmce~d80adb5f",172:"pmce~d939e436",173:"pmce~ee846d98",174:"rde~3333b9b6",216:"vendors~pe~06694820",217:"vendors~pe~0f485567",218:"vendors~pe~55203cfd",219:"vendors~pe~678f84af",220:"vendors~pe~690b702c",221:"vendors~pe~71125b46",222:"vendors~pe~777db305",223:"vendors~pe~82854e37",224:"vendors~pe~8b9d99e7",225:"vendors~pe~9321a7ba",226:"vendors~pe~c59e43b8",227:"vendors~pe~d4945f69",228:"vendors~pe~d80adb5f",229:"vendors~pe~d939e436",230:"vendors~pe~ee846d98",231:"vendors~pe~fc6deeec",232:"vendors~phe~ce5883b0",233:"vendors~phe~eefe6aba",234:"vendors~rde~0f485567",235:"vendors~rde~253ae210",236:"vendors~rde~37904b70",237:"vendors~rde~4e8588b8",238:"vendors~rde~7274e1de",239:"vendors~rde~82be2ce2",240:"vendors~rde~88436a7c",241:"vendors~rde~922e58ef",242:"vendors~rde~b24a28be",243:"vendors~rde~b5a0571e",244:"vendors~rde~cec4ba35",245:"vendors~rde~cf3d4a10",246:"vendors~rde~e65503b9",247:"vendors~rde~f9ca8911",248:"vendors~se~9774f63b",249:"vendors~se~a4f7b5e1",250:"vendors~se~d0fcca00",251:"vendors~ve~2374ce8c",252:"vendors~ve~305045fd",253:"vendors~ve~82be2ce2",254:"vendors~ve~ab8235e0",255:"vendors~ve~cfba5e8d",256:"vendors~xterm~0d30e071",257:"vise~cfba5e8d",258:"vise~da250ca5",259:"vise~e65503b9",260:"xterm~d021be4b"}[e]||e)+"."+{0:"fcd2c1e4",1:"13b92da0",2:"c8e2b124",3:"a73128e0",4:"41d1764c",5:"0b3a1c9b",6:"c0322684",7:"bad556f5",8:"554fad22",9:"22e9ee86",10:"6de42e0b",11:"8f9c87f5",12:"adab0d24",13:"77c1f904",14:"8913b344",15:"0eecfe04",16:"faddb57f",17:"ca08ee5f",18:"da8f30de",19:"5717f891",20:"02a0c2cb",21:"523e42b3",22:"f559dc41",23:"9ed3791b",24:"3bb5e4ae",25:"8c040cad",26:"ccb2b91f",27:"2fe18f7c",28:"faceb724",29:"734cc197",30:"ae99c772",31:"648ff4a6",32:"369dd003",33:"2515f8b3",34:"719d45ec",35:"79670fbd",36:"9f79bd3a",37:"f5137410",38:"a65129e4",39:"6722da76",40:"f6787acc",41:"471d8525",42:"c11574a9",43:"c02442de",44:"fb1b5d0f",45:"4f4dfad5",46:"bb4a32c5",47:"83417e9c",48:"86d0a596",49:"e4828b63",50:"0eb5cf1c",51:"07a49140",52:"7f3a64c0",53:"d9c1e350",54:"1b3bf690",55:"21a66c64",56:"76ddbb82",57:"910f3a93",58:"56c55184",59:"cc917769",60:"4ae907b4",61:"f88944b5",62:"10d47613",63:"182c392e",64:"40f5d5bb",65:"6db43ed7",66:"615c0e36",67:"8486a460",68:"4dd9aaf7",69:"375c4003",70:"465f0e97",71:"f5470916",72:"79349854",73:"063c2a13",74:"50c2132a",75:"cb957d17",76:"752555c2",77:"f9e5d4fd",78:"fd5c05fb",79:"975dce19",80:"8c9481fc",81:"b302f894",82:"420fd0ed",83:"562e54de",84:"bda380c2",85:"443c37b4",86:"ad18be1a",87:"7f6e4ae5",88:"6945b9f2",89:"e9daf9b6",90:"7e4cf8a6",91:"94b57474",92:"02ed3fe5",93:"c3dce8ab",94:"cb47fa55",95:"f11d992e",96:"6adadb7d",97:"16a3cfb0",98:"20e63c84",99:"ad00f7db",100:"5cb57738",101:"1976b22d",102:"1e7db32c",103:"45ff8765",104:"ba484d81",105:"57c8804f",106:"2bb7a6fd",107:"f8b3cab3",108:"1c4dfb82",109:"fe5358f9",110:"7b41b859",111:"e1b798b8",112:"97020441",113:"8605c0c4",114:"09d0e194",115:"fb23c664",116:"fbe25f6f",117:"92b32016",118:"7560ed67",119:"60cf0f1b",120:"675eb2db",128:"2001860b",129:"9fa03146",130:"6855d2ef",131:"dd376b06",132:"41169811",133:"be00cfb8",134:"99d96fe5",135:"f931b2aa",136:"b8355756",137:"36d90828",138:"71cd9f73",139:"c7c3a1fe",140:"a31b7cbf",141:"2160dbbb",142:"ab4558b4",143:"3a9f8528",144:"985b8ae3",145:"e30721a0",146:"938f6be4",147:"f34446db",148:"15812cf2",149:"01aadf04",150:"e5a088dd",151:"2028daac",152:"a1bbf539",153:"884c786d",154:"445cadba",155:"883ee737",156:"5476d6b5",157:"729459a9",158:"3e2f518e",159:"411b7918",160:"a8327c26",161:"30ac7949",162:"759efbfd",163:"9fffeba2",164:"a03fb85f",165:"5a42745e",166:"a06f3009",167:"7246963b",168:"eb8c554d",169:"4f63ed64",170:"24258038",171:"01253bc2",172:"3b73d3f0",173:"a461eda4",174:"09a66d96",216:"529421a5",217:"7b5bf8c6",218:"2a7c6687",219:"ff7bc69b",220:"436b5bb5",221:"0b4b1eb0",222:"91a40bc8",223:"52d7f80e",224:"fe53901d",225:"fe413e03",226:"5dc3d614",227:"4fd96138",228:"0bf1b5f1",229:"eba5285f",230:"108191c8",231:"2b94fe15",232:"edcd8fc8",233:"7388151d",234:"1c3d55a7",235:"854de83b",236:"944d4f07",237:"97b398c0",238:"80ebf4d1",239:"99e7e258",240:"9c370fd1",241:"bdba5bff",242:"35802e4a",243:"96467d82",244:"1a1deff8",245:"f34f6ec6",246:"b4ee0fa8",247:"1c977021",248:"db9e49b0",249:"785bd061",250:"12a61d86",251:"e23490d8",252:"c3a25da3",253:"c6ddee1c",254:"22345a16",255:"a1ec0d36",256:"59ef4222",257:"d13cbe80",258:"4ee60bca",259:"90892af9",260:"67712860",261:"400cbc04",262:"3ee428e2",263:"10ac8b81",264:"98ec5c40",265:"56ba50a9",266:"feb77d25",267:"8bb1b4ce",268:"654a5a42",269:"1fd02aa5",270:"77de18b1"}[e]+".chunk.js"}(e);var r=new Error;n=function(c){b.onerror=b.onload=null,clearTimeout(m);var d=a[e];if(0!==d){if(d){var f=c&&("load"===c.type?"missing":c.type),o=c&&c.target&&c.target.src;r.message="Loading chunk "+e+" failed.\n("+f+": "+o+")",r.name="ChunkLoadError",r.type=f,r.request=o,d[1](r)}a[e]=void 0}};var m=setTimeout((function(){n({type:"timeout",target:b})}),12e4);b.onerror=b.onload=n,document.head.appendChild(b)}return Promise.all(c)},s.m=e,s.c=f,s.d=function(e,c,d){s.o(e,c)||Object.defineProperty(e,c,{enumerable:!0,get:d})},s.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},s.t=function(e,c){if(1&c&&(e=s(e)),8&c)return e;if(4&c&&"object"==typeof e&&e&&e.__esModule)return e;var d=Object.create(null);if(s.r(d),Object.defineProperty(d,"default",{enumerable:!0,value:e}),2&c&&"string"!=typeof e)for(var f in e)s.d(d,f,function(c){return e[c]}.bind(null,f));return d},s.n=function(e){var c=e&&e.__esModule?function(){return e.default}:function(){return e};return s.d(c,"a",c),c},s.o=function(e,c){return Object.prototype.hasOwnProperty.call(e,c)},s.p="/campus/",s.oe=function(e){throw console.error(e),e};var b=this["webpackJsonpcampus-app-v2"]=this["webpackJsonpcampus-app-v2"]||[],r=b.push.bind(b);b.push=c,b=b.slice();for(var m=0;m<b.length;m++)c(b[m]);var v=r;d()}([])</script><script src="/campus/static/js/vendors~main~253ae210.d41a5d28.chunk.js"></script><script src="/campus/static/js/vendors~main~0f485567.8a2d30d4.chunk.js"></script><script src="/campus/static/js/vendors~main~cfba5e8d.be01dfee.chunk.js"></script><script src="/campus/static/js/vendors~main~eefe6aba.a7063f59.chunk.js"></script><script src="/campus/static/js/vendors~main~3d4ff91f.6a776873.chunk.js"></script><script src="/campus/static/js/vendors~main~977b87ed.b196b27e.chunk.js"></script><script src="/campus/static/js/vendors~main~ea2ee6ce.4983203b.chunk.js"></script><script src="/campus/static/js/vendors~main~7af1ae76.e564904f.chunk.js"></script><script src="/campus/static/js/vendors~main~b24a28be.93fcb2ab.chunk.js"></script><script src="/campus/static/js/vendors~main~2374ce8c.810cbcd7.chunk.js"></script><script src="/campus/static/js/vendors~main~975751f9.9d749f83.chunk.js"></script><script src="/campus/static/js/vendors~main~f6d28abc.9d3f724a.chunk.js"></script><script src="/campus/static/js/vendors~main~cdf51222.0498d26a.chunk.js"></script><script src="/campus/static/js/vendors~main~89b1000f.14a090c8.chunk.js"></script><script src="/campus/static/js/vendors~main~60b88c48.e340e499.chunk.js"></script><script src="/campus/static/js/vendors~main~e4d02240.44e5a604.chunk.js"></script><script src="/campus/static/js/vendors~main~13f6a649.5c95a3ad.chunk.js"></script><script src="/campus/static/js/vendors~main~7274e1de.a906fe8f.chunk.js"></script><script src="/campus/static/js/vendors~main~b5906859.0aa8a4bb.chunk.js"></script><script src="/campus/static/js/vendors~main~db300d2f.1444a175.chunk.js"></script><script src="/campus/static/js/vendors~main~1f20a385.9a81ad2a.chunk.js"></script><script src="/campus/static/js/vendors~main~7d359b94.b2e9ad0c.chunk.js"></script><script src="/campus/static/js/vendors~main~4d01349d.3f4d2495.chunk.js"></script><script src="/campus/static/js/vendors~main~d4b3742f.c9b16076.chunk.js"></script><script src="/campus/static/js/vendors~main~690b702c.74b4472c.chunk.js"></script><script src="/campus/static/js/vendors~main~2930ad93.8393a8e4.chunk.js"></script><script src="/campus/static/js/vendors~main~bc6b49b0.6cf25bb6.chunk.js"></script><script src="/campus/static/js/vendors~main~9c5b28f6.bb5817e4.chunk.js"></script><script src="/campus/static/js/vendors~main~678f84af.755a20a7.chunk.js"></script><script src="/campus/static/js/vendors~main~3f764be9.826d2fe2.chunk.js"></script><script src="/campus/static/js/vendors~main~3c941b24.217ec06f.chunk.js"></script><script src="/campus/static/js/vendors~main~98431bb7.e086e92c.chunk.js"></script><script src="/campus/static/js/vendors~main~d51fa4e6.1fc8fae3.chunk.js"></script><script src="/campus/static/js/vendors~main~f53fef7e.fb15d7a2.chunk.js"></script><script src="/campus/static/js/vendors~main~d84fb1a9.0631ed9c.chunk.js"></script><script src="/campus/static/js/vendors~main~8e7b4e02.df95baa3.chunk.js"></script><script src="/campus/static/js/vendors~main~33237170.d809ac40.chunk.js"></script><script src="/campus/static/js/vendors~main~ec8c427e.6211cca3.chunk.js"></script><script src="/campus/static/js/vendors~main~1c3a2c3f.9cba5440.chunk.js"></script><script src="/campus/static/js/vendors~main~2900d54e.2b8e0fa0.chunk.js"></script><script src="/campus/static/js/main~748942c6.866f5659.chunk.js"></script><script src="/campus/static/js/main~21833f8f.a974c51c.chunk.js"></script><script src="/campus/static/js/main~b553cb79.e3106c6e.chunk.js"></script><script src="/campus/static/js/main~970f9218.afa96ae2.chunk.js"></script><script src="/campus/static/js/main~e2550e02.95d6efa8.chunk.js"></script><script src="/campus/static/js/main~c714bc7b.f303fa6c.chunk.js"></script><script src="/campus/static/js/main~315ba38e.9f76f708.chunk.js"></script></body></html>